PretrainedConv1D + Conv2D | Decoder frozen | Dual MSE lambda = 0.5 
PretrainedConv1D + Conv2D | Decoder frozen | Dual MSE lambda = 0.7 
PretrainedConv1D + Conv2D | Encoder+Decoder frozen | Dual MSE lambda = 0.5 
PretrainedConv1D + Conv2D | Encoder+Decoder frozen | Dual MSE lambda = 0.7
PretrainedConv1D + Conv2D | Encoder+Decoder frozen | Dual MSE lambda = 0.9 
Best model of the 4: Without Layer Norm | Without weight decay
Best model of the 4: Without Layer Norm | With weight decay
Best model of the 4: With Layer Norm | With weight decay
Best model of the 7: With SqueezeExcitation layer
X Model using arithmetic encoder / hyperprior
1D transformer auf BERT Basis
2D transformer auf ViT Basis

VAE | With batching