\thispagestyle{empty}
\vspace*{1.4cm}

\begin{center}
    {\Large \textbf{Abstract}}
\end{center}

\vspace*{0.5cm}

\noindent
Learning-based hyperspectral image compression is an increasingly important field of study in the field of remote sensing. This thesis proposes the Combined Model, a novel, highly flexible architecture to perform image compression exploiting both spatial and spectral dependencies of hyperspectral image data. The Combined Model allows for the combination of different spectral and spatial autoencoder models. It further allows spatial autoencoder methods that are optimised for image compression on RGB or multispectral images to be used in the domain of hyperspectral imaging. We propose multiple spectral and spatial models to be used as part of the Combined Model and a training methodology specific to the Combined Model as well as a novel loss function. The models are evaluated on the large-scale hyperspectral image dataset HySpecNet-11k. We analyse the different aspects of the Combined Model architecture and its training process and compare the achieved reconstruction accuracy for multiple compression ratios. The results show that the Combined Model architecture significantly improves upon state-of-the-art learning-based hyperspectral image compression methods as well as JPEG 2000 for low and very low bitrates.
\\