\chapter{Introduction\label{cha:chapter1}}
Hyperspectral imaging is a quickly growing field. It is the technique of capturing images with a specialized camera in order to obtain a spectrum of many wavelengths of light for each pixel of a taken image. TODO 

There are many applications for the use of these images as much information can be extracted from the combination of spatial and spectral data in them. One such application is in agriculture where classification of hyperspectral images is used to detect the presence of the toxic metal cadmium in soil, lessening the need for chemical methods that require the plant to be harvested to test for cadmium stress. Using hyperspectral imaging the detection of cadmium can be performed on living plants \citep{zea_leveraging_2022}. Hyperspectral imaging is also being used to separate plastic waste where a machine learning model based on hyperspectral images can separate twelve kinds of plastics better than previously used methods such as near-infrared technology \citep{henriksen_plastic_2022}.

Another field where the use of hyperspectral imaging is rising in importance is in geology and environmental sciences. An example of this is the \ac{enmap} mission which launched a satellite into earths orbit in 2022 that takes images of the surface of the earth with a comparatively high spatial resolution, allowing for regional geographic analysis \citep{guanter_enmap_2015}.
This has already lead to many interesting studies including of glacier ice surface properties of the Ice Sheet in South-West Greenland, moisture content of soil below grassland and identification of specific crop traits such as the chlorophyll content or the leaf water content \citep{bohn_glacier_2022}\citep{pascual-venteo_prototyping_2022}\citep{dopper_estimating_2022}.
A dataset created from the images produced by the \ac{enmap} mission is also the main dataset studied in this thesis.

The increasing usage of hyperspectral imaging makes it essential to address the disadvantages of the technology. One major disadvantage of this type of imaging is the required amount of disk space for the resulting images. Because there are many more spectral bands compared to the three bands of red, green and blue in traditional photography the resulting file size rises accordingly. Furthermore, hyperspectral images often use high precision for the specific brightness values captured for each point in the pixel-band data cube. The \ac{enmap} satellite images are composed of 32 bit values, while in \ac{rgb} imaging 8 bits per pixel per band are most common \citep{guanter_enmap_2015}. TODO SOURCE. A hyperspectral image might for example have 300 bands. In combination with 32 bit values per pixel per band the resulting file size would be 400 times larger than an \ac{rgb} image with the same pixel density. In addition to this it is important to notice that even \ac{rgb} images need to be compressed for many use cases in order to be efficiently stored and transmitted, which is why there are many compression standards for \ac{rgb} images in wide usage.
Furthermore, compression of hyperspectral images is a complex problem. This arises from the combination of spatial image compression complexities and the added challenge of encoding information in the spectral dimension which \ac{rgb} compression algorithms do not consider. The latter is one of the reasons why many \ac{rgb} compression algorithms do not perform well on hyperspectral data as will be shown in this thesis. In addition to this there are more technical reasons for the difficulty of adapting algorithms for \ac{rgb} compression that will also be explored in this thesis. For the above mentioned reasons it is clear that it is important to research compression algorithms for hyperspectral images.

Possible algorithms for image compression can be categorized into multiple broad groups. They can firstly be grouped by whether they compress the image losslessly or with loss. Lossless algorithms restore the compressed image exactly whereas lossy reconstructions cause distortion. The disadvantage of lossless compression is however that there are mathematical limits to the compression rate given by the entropy in the data that is to be compressed. Lossy compression methods can instead adapt their rate of compression based on either the desired amount of distortion or the target compression rate. They can also be combined with a lossless compression method to further optimise their compression rate. For these reasons this thesis focuses on lossy compression methods.

The category of lossy compression algorithms can be further divided into traditional compression methods and the learning-based compression methods. Traditional compression methods employ algorithms such as the discrete cosine transform which is used in the JPEG image compression standard or the wavelet transform, often in combination with a lossless entropy coding method. Learning-based approaches use the powerful capability of artificial neural networks to universally approximate arbitrary functions using gradient descentCITATION. These networks are then used to build models that learn to compress and decompress images. Lately these networks have been shown to outperform traditional compression methods for many applications, especially for \ac{rgb} images.
Compression for hyperspectral images is in the early stages of research, however even in this domain there are promising results showing the capabilities of learned autoencoders for this task.

\section{Objective\label{sec:objective}}
This thesis addresses the problem of hyperspectral image compression using machine learning models consisting of two parts, an encoder and a decoder.\\
The encoder learns to map the original image to a low-dimensional latent space, thereby performing compression. Analogously, the decoder is trained to reconstruct the input by mapping elements from this latent dimension to full-size images that are as close as possible to the original image.

Contributions to the research in on learned hyperspectral image compression are made in this thesis by introducing a new architecture that enables the use of spatial compression algorithms such as models that might be used for \ac{rgb} image compression by combining them with a model that performs compression in the spectral domain while keeping spatial relationships intact. In this way, it is possible to compress the spatial information in hyperspectral images using models that are not ordinarily applicable to these images.

Using this architecture, multiple model combinations are designed and compared with each other as well as with the base versions of these models.\\
These models include models based on \acp{cnn} as well as transformer-based architectures.
A model using a hyperprior architecture is also used for the spatial compression. This architecture yields much higher compression ratios than other models by using an arithmetic encoder in the bottleneck. With this model compression ratios much higher than the current state of the art for hyperspectral image compression are achieved while distortion is only reduced by a comparatively small amount. TODO besser formulieren, bzw. überlegen wie viel hier erklärt werden sollte zu hyperprior etc.

Additionally, the latent spaces of both the encoder in the spectral domain as well as the latent space of the spatial encoder will be analysed.

\section{Outline\label{sec:outline}}
This section gives a brief introduction into the chapters in the thesis, which is split into 7 chapters.

\textbf{\autoref{cha:chapter2}} presents the related work. This relates to the research of learning-based hyperspectral image compression by itself. However, as learning-based compression for hyperspectral images, in contrast to traditional hyperspectral compression methods, is a recent and relatively unexplored field of study, the adjacent research topic of learned \ac{rgb} image compression is also explored. There is also some exploration of the general studies done on convolutional neural networks as well as transformers.

\textbf{\autoref{cha:chapter3}} gives an overview of the theoretical ideas used in the proposed methods, such as \acp{cnn}, transformers, arithmetic coding as well as the hyperprior architecture for compression.

\textbf{\autoref{cha:chapter4}} details the individual submodels making up the models that are proposed to address the hyperspectral image compression problem as well as the models in their totality. It also gives an overview over the loss functions used for training the models, one of which is a loss function specifically designed for the models proposed in this thesis.

\textbf{\autoref{cha:chapter5}} explains the design of the experiments done, the dataset that is used for these experiments as well as the results of these experiments. It also details some of the challenges encountered during the experimentation phase.

\textbf{\autoref{cha:chapter6}} gives a summary of the results from the thesis as well as possible improvements that could be made as well as ideas that could be explored in future research.