\chapter{Related Work\label{cha:chapter2}}
Learning-based hyperspectral image compression is a developing field of study. While there are papers published on this topic, there are some problems making it difficult to assess and compare the results of these studies, as will be explored further in this chapter. An overview of hyperspectral image compression algorithms by Dua et al. \citep{dua_comprehensive_2020} shows the discrepancy between traditional transform-based and prediction-based compression techniques and techniques based on machine learning. The review contains 21 transform-based and 19 prediction-based techniques but only five learning-based models. While the overview of the models based on machine learning is no longer complete since the review was done in 2020, it still shows that learning-based approaches for hyperspectral image compression until recently only received limited attention from the research community. Lately, however, research in this field has been increasing quickly.
Since learning-based \ac{rgb} image compression is a closely related field and much more widely researched, relevant studies done regarding this topic are also analysed.
\section{Hyperspectral Image Compression \label{sec:ch2hyperspectral}}
Most learning-based hyperspectral image compression research employs a \ac{cnn}-based model architecture to reduce the dimensions of the input image \citep{kuester_1d-convolutional_2021,kuester_transferability_2022,la_grassa_hyperspectral_2022}. Another model proposed by Guo et.al. \citep{guo_learned_2021} uses a hyperprior architecture, originally developed by Ball√© et al. \citep{balle_end--end_2017}, which also uses convolutional layers in an \ac{ann} but combines them with an arithmetic coder to improve compression rate.
Some other models that will be explored later are a model based on a \ac{svm} by Aidini et al. \citep{aidini_hyperspectral_2019}, a \ac{gan} model by Deng et al. \citep{deng_learning-based_2020} and a model using a simple \ac{mlp} by Kumar et.al. \citep{leal-taixe_onboard_2019}. Before detailing these methods, an overview of some traditional hyperspectral image compression architectures is given.
\subsection{Traditional Architectures}
Dua et al. \citep{dua_comprehensive_2020} describe eight categories of hyperspectral image compression techniques, one of which is learning-based approaches. Of the traditional methods, that is methods not based on machine learning, the most researched categories are transform-based techniques and prediction-based techniques. Transform-based techniques work by transforming the spatial dimension, the spectral dimension or both into the frequency domain by using a transformation function that is applied to the input image \citep{dua_comprehensive_2020}. Possible transformation functions are the \ac{klt}, the \ac{dct}, the \ac{dft} or a \ac{dwt}. The transformation can then be used to decorrelate the image in the spatial, spectral or both domains depending on the specific technique used. More specifically, the \ac{klt} directly decorrelates the data, while for the other transformation functions additional algorithms are commonly used to decorrelate the coefficients resulting from the transformation \citep{saghri_adaptive_2010,karami_compression_2012}. After decorrelation, the coefficients are quantized by removing coefficients that are close to zero \citep{dua_comprehensive_2020}. The quantized coefficients are then compressed further using an entropy coding algorithm in the final step of compression. Decompression is possible because the used transformation functions are invertible, although loss is introduced during the quantization step. Some of these general steps may be modified for specific transform-based architectures.

Looking at a specific example of a transform algorithm, Karami et al. \citep{karami_compression_2012} use a two-dimensional \ac{dwt} in combination with the \ac{td} algorithm, an extension of \ac{pca}, to reduce correlation. They apply the 2\ac{dwt} to each spectral band of the input image and obtain four tensors containing the coefficients for each band. The \ac{td} algorithm is then used to decorrelate the coefficients both in the spatial and spectral domain. The least significant coefficients are then removed using an iterative process before the remaining coefficients are compressed using the entropy coding technique of arithmetic coding.

The other common category of traditional hyperspectral image compression techniques is prediction-based approaches. These approaches compress images by predicting pixel values from the other values of the other pixels using some algorithm and then only storing the prediction residuals \citep{dua_comprehensive_2020,conoscenti_constant_2016}. The current compression standard proposed by the \ac{ccsds}, CCSDS 123.0-B2, is a prediction-based approach \citep{hernandez-cabronero_ccsds_2021}. The predictor for this standard predicts a pixel value by computing the sum of its neighbours \citep{conoscenti_constant_2016}. The difference between these sums and the original pixel values is then stored in a local difference vector which can then be compressed using an entropy coder.
\subsection{Learning-based Architectures}
In contrast to the traditional methods, learning-based architectures use \acp{ann} trained using gradient descent to learn a mapping from the space of input images to a latent space \citep{ruder_overview_2017}. In image compression, this latent space is lower-dimensional than the input space, thereby performing compression. 
The most common approach for learning-based hyperspectral compression is \ac{cnn}-based architectures. These architectures can be split into two categories, the first being the models using \ac{twod} convolutional layers to learn the spatial dependencies of the hyperspectral images \citep{la_grassa_hyperspectral_2022}. The second category is models using \ac{oned} convolutional layers to learn the spectral dependencies of the input data \citep{kuester_1d-convolutional_2021,kuester_transferability_2022}. This thesis proposes the first purely \ac{cnn}-based approach using both the spatial and the spectral dependencies of hyperspectral images for compression. The model proposed by Guo et.al. \citep{guo_learned_2021} utilises both spatial and spectral dependencies, it does however rely on a hyperprior architecture and is therefore not a purely \ac{cnn}-based model. This model as well as the hyperprior architecture will be detailed later in this chapter.
As mentioned above, comparing the results from these papers directly is difficult. The reason for this is that the models use different datasets since there is currently no accepted standard dataset for hyperspectral image compression. Furthermore, the models are designed for different compression rates. Since a higher compression rate also leads to a higher distortion for the same model in most cases as described by rate-distortion theory \citep{berger_rate-distortion_2003}, this makes it hard to directly compare the results from papers that use both a different dataset and different compression rates, therefore requiring a reimplementation of the models in order to be able to fairly compare them.

A model exploiting only the spectral dependencies in the input images is provided by Kuester et al. \citep{kuester_1d-convolutional_2021,kuester_transferability_2022}. They use a model consisting of a \ac{oned} convolutional layer to learn spectral dependencies followed by a max pooling layer applied to the spectral dimension to reduce the dimensionality of the image. This block of \ac{oned} convolutional layer and a max pooling layer is repeated, using \ac{lrelu} as the activation function. Following that, two more \ac{oned} convolutional layers are added, now without max pooling layers in between. Each convolutional layer uses fewer filters than the layer before it. Finally, the last layer uses only one filter, thereby providing the bottleneck of the compression algorithm with a fixed compression rate of 4. Decompression is performed using a reversed model, symmetrical to the encoder. The decoder only differs by replacing the blocks consisting of a convolutional and a max pooling layer by transposed \ac{oned} convolutional layers with a stride of two to increase the spectral dimensionality instead of reducing it \citep{kuester_transferability_2022}. In an earlier variation of the model, upsampling layers are used instead for this purpose \citep{kuester_1d-convolutional_2021}. In contrast to most other models, this model is trained and applied not to a whole image at once, but rather to each pixel individually. This has the advantage of reducing the complexity of the task the model has to perform. Instead of compressing a complete hyperspectral image, the model only learns to compress the spectral signatures of arbitrary pixels from these images. The number of training samples also increases dramatically, as each hyperspectral image consists of many pixels, although each training sample contains much less information than it does for a model that trains on complete images at once. A disadvantage of the approach is that modelling spatial dependencies is not possible using a per-pixel training approach. Furthermore, training is much slower when compared to other models. The reasons for this and more detailed comparisons with other model architectures are explored in \autoref{cha:chapter5}.

In contrast to the aforementioned model, La Grassa et al. \citep{la_grassa_hyperspectral_2022} propose a model that focuses on the spatial dependencies in the image data. This model is trained and applied to complete hyperspectral images in one step. They use a combination of \ac{twod} convolutional layers and max pooling layers applied to the spatial dimension of an input image to reduce the spatial dimensionality while simultaneously increasing the number of filters in the convolutional layers to keep the amount of stored information stable. After multiple of these blocks, the output of the last block is flattened into a single dimension, followed by a linear layer that maps that output into a one-dimensional latent space of the chosen size. The decoder is again a symmetrical, reversed version of the encoder, replacing only the blocks of \ac{twod} convolutional and max pooling layers by transposed convolutional layers with a stride of 2. This model has the advantage of having the ability to set a precise bit rate by changing the output dimensions of the final linear layer. However, applying the model to hyperspectral images with many bands is difficult. This is because, in the proposed model, the first convolutional layer uses 64 filters. Since this layer is applied to the complete input image, an input image with dimensions (C,H,W) where C is the number of spectral bands and H and W are the height and width of the image respectively is transformed into the dimensions (64,H,W). If C is significantly higher than 64, this leads to large information loss in the first layer. This is common in hyperspectral datasets. This can be seen in the HySpecNet-11k dataset \citep{fuchs_hyspecnet-11k_2023}, the main dataset used in this thesis, which uses 202 channels. Possible solutions to this problem are explored in \autoref{cha:chapter4}.

Some approaches do not use a \ac{cnn}-based architecture. While some of these architectures use models that contain a \ac{cnn} in addition to other parts, some architectures use different model types completely. Among these are both different types of neural networks as well as learning-based algorithms not using neural networks.
One such architecture is proposed by Aidini et al. \citep{aidini_hyperspectral_2019}. They use quantization to compress the original image, meaning that the precision of the spatial and spectral values of the image is decreased. Then an algorithm tries to recover the original tensor values by trying to reconstruct low-rank tensors as a constrained optimization problem. Afterwards, a spatial super-resolution algorithm using trained dictionary learning is used to increase the resolution of this image, after which a classifier is trained on these super-resolved images. While this architecture is interesting, it is not directly used in this thesis as its methodology is very different to the neural network-based methodologies used in the thesis.

Another category of models uses \acp{ann} to determine parameters for lossless compression algorithms. Shen et al. \citep{shen_golomb-rice_2017} use a deep belief network to determine the optimal parameters for Golomb-rice coding, a lossless coding algorithm that normally assumes a geometric underlying distribution. Using a neural network to determine the parameter removes that necessity.
This core strategy is also used by Guo et al. \citep{guo_learned_2021}. They use a hyperprior architecture to compress hyperspectral images. Hyperprior models use an \ac{ann}-based model to transform the image data into a latent space that is commonly lower-dimensional than the input image. Then a second \ac{ann} is trained on the latent space to determine parameters for an arithmetic coder, a lossless coding algorithm. In both Guo et al. and the original paper introducing the hyperprior architecture for \ac{rgb} images, Ball√© et al. \citep{balle_end--end_2017}, both \acp{ann} are \acp{cnn} and the latent space is indeed a lower-dimensional space.

Guo et al. innovate on the original approach in the fact that they assume a student's T distribution instead of a Gaussian distribution for the arithmetic coder and in the design of the first \ac{cnn}. Their version includes both a spatial and a spectral part in the main \ac{cnn}, making it the only model to learn both spatial and spectral information for hyperspectral image compression. They achieve this by using 2-D convolutional layers for the spatial domain and 3-D convolutional layers with a kernel size of one in the spatial dimensions to include the spectral dependencies. However, a disadvantage of their model is that it is developed only for datasets with a low amount of channels compared to other hyperspectral datasets with the highest having 102 spectral channels. The approach is also not easily adaptable to datasets with a much higher number of channels. This is because the first convolutional layer of the model uses 192 filters and a stride of two, therefore transforming an input image with the dimensions (C, H, W), where C is the number of spectral channels and H and W are the height and width respectively, into the dimensions (192, H/2, W/2). For one of the two datasets studied by Guo et al., the KAIST dataset, which contains 31 spectral channels, is a large increase in information. For the other dataset, ROSIS-Pavia, with 102 to 103 spectral channels depending on the scene, this is already a loss of information, requiring the first layer to encode some of the spatial information of the image appropriately in order to not introduce large amounts of distortion. For datasets with more channels, this problem increases. Furthermore, because of \ac{gpu} memory limitations, increasing the number of filters appropriately is not always possible.

Another model using neural networks is proposed by Kumar et al. \citep{leal-taixe_onboard_2019}. Instead of \acp{cnn}, they use a simple multi-layer perceptron as the decoder for the reason that they use this model for real-time onboard image compression which requires a much more simple model for faster execution speed. Another uncommon trait of their architecture is that they do not use a symmetric model, meaning that the encoder and decoder are mirrors of one another. Instead, they only use an \ac{ann} for the decoder and use a low-complexity encoder based on matrix multiplication.
Hong et al. \citep{hong_spectralformer_2022} propose a novel architecture as well. They use a transformer that works on spectral embedding by linearly projecting groups of neighbouring spectral bands to an embedding vector. This improves the capabilities of the network since neighbouring bands in hyperspectral images capture detailed changes in the absorption of the underlying material and therefore contain important information, especially for classification tasks.
In addition to this, they implement \ac{caf} to improve the exchange of information in the transformer section of the model. This means that they use multiple transformer layers and, in addition to the direct connection between adjacent transformer layers, add connections that skip one layer and connect with the layer after using a special CAF module.
The transformers can be applied either per pixel or for small patches. However, their work is not used in the context of image compression but rather image classification and therefore only contains an encoder combined with an \ac{mlp} head to classify hyperspectral image pixels or patches based on categories such as "Corn", "Grass Pasture" or "Wheat". This means that an application of this architecture to the task of image compression would require substantial additions to the model. 
\section{RGB Image Compression \label{sec:ch2rgb}}
While the research into hyperspectral image compression strongly increased in recent years, \ac{rgb} image compression has been a widely researched field for many years. There are many traditional compression algorithms, some of which are installed on every modern operating system and browser. Examples of these are \ac{png}, a lossless image compression format as well as \ac{jpeg}, a collection of compression algorithms, the most common of which performs lossy compression of images. An improved version of \ac{jpeg}, \ac{jpeg} 2000, also exists, offering increased compression rate for similar distortion values \citep{fowler_three-dimensional_2007}.
However, while these algorithms are very popular, learning-based image compression has outperformed methods such as \ac{jpeg} in both compression ratio and distortion \citep{balle_end--end_2017,balle_variational_2018}. Furthermore, many of the ideas in learning-based hyperspectral image compression originate from \ac{rgb} image compression studies and many of the ideas in \ac{rgb} image compression have not yet been adapted to the hyperspectral realm. For these reasons, \ac{rgb} image compression papers are directly relevant even for a thesis that only concerns itself with the hyperspectral domain.
\subsection{The Hyperprior Architecture}
One of the most important recent works in \ac{rgb} image compression was released by Ball√© et al. \citep{balle_variational_2018}. The model proposed in this builds on a previous work \citep{balle_end--end_2017} using a \ac{cnn} to reduce the dimensionality of the input image, followed by a quantization of the resulting latent and the usage of an arithmetic autoencoder to losslessly compress the quantized latent. The output of the arithmetic autoencoder is then decoded by a \ac{cnn} that is symmetrical to the encoder \ac{cnn}, similar to the models for hyperspectral image compression that were discussed previously. This model already outperformed \ac{jpeg} and the improved \ac{jpeg} 2000 on the tested data.

The performance of the arithmetic autoencoder depends on the accuracy of the estimated probability distribution that is used to compress the given data. In this area, improvements were made in Ball√© et al. \citep{balle_variational_2018} by using a smaller, separate \ac{cnn} that learns to extract parameters for a good probability distribution estimate from the latent resulting from the main \ac{cnn}. This network also uses an autoencoder structure, meaning that the estimate can also be transmitted in compressed form as side channel information using only a small amount of bits. Training a network using gradient descent for this purpose would not ordinarily be possible since the quantized latents have discrete values resulting in zero gradients everywhere. For this reason, the quantization is substituted during training by the addition of a small amount of uniform noise to dediscretize the latents.\\
This hyperprior architecture is used in a large portion of modern learning-based \ac{rgb} image compression models, among these also the hyperspectral image compression model by Guo et al. \citep{guo_learned_2021} which was discussed in Chapter \ref{sec:ch2hyperspectral}.

One such example is a paper by Hu et.al. \citep{hu_coarse--fine_2020} where the model is generalised to include not only two but an adaptable number of \acp{cnn}, where each \ac{cnn} learns the probability distribution of the \ac{cnn} before it. This leads to slight improvements in the bitrate of the model while not changing the distortion. The distortion remains unchanged since the only loss occurs within the first \ac{cnn} which compresses the input image. The other \acp{cnn} is only used to improve the performance of the lossless arithmetic coders.

The architecture was also further improved in two ways by Minnen et al. \citep{minnen_joint_2018}. The first improvement is a generalisation in the structure of the probability distribution from the original scale mixture of Gaussians \citep{wainwright_scale_1999} to a Gaussian mixture model. Therefore, the second \ac{cnn} generating the probability distribution parameters has to predict both a scale and a mean instead of only a scale as before. This allows for better modelling of the true underlying distribution and the paper shows that the increase in necessary side-channel information is lesser than the improvement created by the improvement in probability distribution prediction.
The second new idea is the addition of an autoregressive model over the latents of the first, main \ac{cnn}. This also improves compression performance as more structure from the latents can be exploited, it does however also increase the computational costs of the network as autoregressive models cannot be trained in parallel. 

Another application of the hyperprior architecture is found in Cheng et al. \citep{cheng_learned_2020}. They improve on the hyperprior model including a joint autoregressive model given by Minnen et al. \citep{minnen_joint_2018} by introducing self-attention modules into the encoder and the decoder \ac{cnn}. Self-attention modules are an idea taken from the field of \ac{nlp}. There it is used as an integral part of the novel transformer architecture, which yields state-of-the-art results in machine translation and other \ac{nlp} fields \citep{vaswani_attention_2017}. In computer vision, it has been used in order to generate attention masks that enable the model to use more bits for the more important parts of an image such as foreground or high-contrast elements and fewer bits for the less important parts of an image \citep{liu_non-local_2019,li_learning_2017,mentzer_conditional_2019}. This approach of using self-attention modules is also the one used by Cheng et al. They model the architecture of their self-attention blocks by using a simplified version of the architecture proposed in Liu et al. \citep{liu_non-local_2019}. The simplification is achieved by removing the non-local blocks, which reduces the training time by four times in their testing while achieving a similar loss \citep{cheng_learned_2020}.
