
@article{de_carvalho_junior_spectral_2000,
	title = {Spectral Correlation Mapper ({SCM}): An Improvement on the Spectral Angle Mapper ({SAM})},
	shorttitle = {Spectral Correlation Mapper ({SCM})},
	author = {de Carvalho Júnior, Osmar and Meneses, Paulo},
	date = {2000-01-01},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\TVIB6KNC\\de Carvalho Júnior and Meneses - 2000 - Spectral Correlation Mapper (SCM) An Improvement .pdf:application/pdf},
}

@incollection{fowler_three-dimensional_2007,
	title = {Three-Dimensional Wavelet-Based Compression of Hyperspectral Imagery},
	isbn = {978-0-470-12462-8},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470124628.ch14},
	abstract = {This chapter contains sections titled: Introduction Embedded Wavelet-Based Compression of 3D Imagery Performance Measures for Hyperspectral Compression Prominent Techniques for Significance-Map Coding {JPEG}2000 Encoding Strategies Compression Performance Summary References},
	pages = {379--407},
	booktitle = {Hyperspectral Data Exploitation},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Fowler, James E. and Rucker, Justin T.},
	urldate = {2022-10-01},
	date = {2007},
	langid = {english},
	doi = {10.1002/9780470124628.ch14},
	note = {Section: 14
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470124628.ch14},
	keywords = {hyperspectral compression performance measures, significance-map coding in hyperspectral imagery, three-dimensional hyperspectral imagery wavelet-based compression},
	file = {Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\E7N66AJA\\9780470124628.html:text/html},
}

@article{du_low-complexity_2008,
	title = {Low-Complexity Principal Component Analysis for Hyperspectral Image Compression},
	volume = {22},
	issn = {1094-3420, 1741-2846},
	url = {http://journals.sagepub.com/doi/10.1177/1094342007088380},
	doi = {10.1177/1094342007088380},
	abstract = {Principal component analysis ({PCA}) is an effective tool for spectral decorrelation of hyperspectral imagery, and {PCAbased} spectral transforms have been employed successfully in conjunction with {JPEG}2000 for hyperspectral image compression. However, the computational cost of determining the data-dependent {PCA} transform is high because of its traditional eigendecomposition implementation which requires calculation of a covariance matrix across the data. Several strategies for reducing the computation burden of {PCA} are explored, including both spatial and spectral subsampling in the covariance calculation as well as an iterative algorithm that circumvents determination of the covariance matrix entirely. Experimental results investigate the impacts of such low-complexity {PCA} on {JPEG}2000 compression of hyperspectral images, focusing on rate-distortion performance as well as data-analysis performance at an anomaly-detection task.},
	pages = {438--448},
	number = {4},
	journaltitle = {The International Journal of High Performance Computing Applications},
	shortjournal = {The International Journal of High Performance Computing Applications},
	author = {Du, Qian and Fowler, James E.},
	urldate = {2022-10-01},
	date = {2008-11},
	langid = {english},
	file = {Du and Fowler - 2008 - Low-Complexity Principal Component Analysis for Hy.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\667RIT6K\\Du and Fowler - 2008 - Low-Complexity Principal Component Analysis for Hy.pdf:application/pdf},
}

@misc{balle_variational_2018,
	title = {Variational image compression with a scale hyperprior},
	url = {http://arxiv.org/abs/1802.01436},
	doi = {10.48550/arXiv.1802.01436},
	abstract = {We describe an end-to-end trainable model for image compression based on variational autoencoders. The model incorporates a hyperprior to effectively capture spatial dependencies in the latent representation. This hyperprior relates to side information, a concept universal to virtually all modern image codecs, but largely unexplored in image compression using artificial neural networks ({ANNs}). Unlike existing autoencoder compression methods, our model trains a complex prior jointly with the underlying autoencoder. We demonstrate that this model leads to state-of-the-art image compression when measuring visual quality using the popular {MS}-{SSIM} index, and yields rate-distortion performance surpassing published {ANN}-based methods when evaluated using a more traditional metric based on squared error ({PSNR}). Furthermore, we provide a qualitative comparison of models trained for different distortion metrics.},
	number = {{arXiv}:1802.01436},
	publisher = {{arXiv}},
	author = {Ballé, Johannes and Minnen, David and Singh, Saurabh and Hwang, Sung Jin and Johnston, Nick},
	urldate = {2022-10-01},
	date = {2018-05-01},
	eprinttype = {arxiv},
	eprint = {1802.01436 [cs, eess, math]},
	note = {Number: {arXiv}:1802.01436},
	keywords = {Computer Science - Information Theory, Electrical Engineering and Systems Science - Image and Video Processing, {RGB}},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\C3LJ7W7J\\Ballé et al. - 2018 - Variational image compression with a scale hyperpr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\9U5KFP5D\\1802.html:text/html},
}

@misc{lu_transformer-based_2021,
	title = {Transformer-based Image Compression},
	url = {http://arxiv.org/abs/2111.06707},
	doi = {10.48550/arXiv.2111.06707},
	abstract = {A Transformer-based Image Compression ({TIC}) approach is developed which reuses the canonical variational autoencoder ({VAE}) architecture with paired main and hyper encoder-decoders. Both main and hyper encoders are comprised of a sequence of neural transformation units ({NTUs}) to analyse and aggregate important information for more compact representation of input image, while the decoders mirror the encoder-side operations to generate pixel-domain image reconstruction from the compressed bitstream. Each {NTU} is consist of a Swin Transformer Block ({STB}) and a convolutional layer (Conv) to best embed both long-range and short-range information; In the meantime, a casual attention module ({CAM}) is devised for adaptive context modeling of latent features to utilize both hyper and autoregressive priors. The {TIC} rivals with state-of-the-art approaches including deep convolutional neural networks ({CNNs}) based learnt image coding ({LIC}) methods and handcrafted rules-based intra profile of recently-approved Versatile Video Coding ({VVC}) standard, and requires much less model parameters, e.g., up to 45\% reduction to leading-performance {LIC}.},
	number = {{arXiv}:2111.06707},
	publisher = {{arXiv}},
	author = {Lu, Ming and Guo, Peiyao and Shi, Huiqing and Cao, Chuntong and Ma, Zhan},
	urldate = {2022-10-01},
	date = {2021-11-12},
	eprinttype = {arxiv},
	eprint = {2111.06707 [cs, eess]},
	note = {Number: {arXiv}:2111.06707},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, {RGB}, Computer Science - Computer Vision and Pattern Recognition, Transformer},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CKTYQ84K\\Lu et al. - 2021 - Transformer-based Image Compression.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\WR8EMMFQ\\2111.html:text/html},
}

@inproceedings{zou_devil_2022,
	title = {The Devil Is in the Details: Window-Based Attention for Image Compression},
	url = {https://openaccess.thecvf.com/content/CVPR2022/html/Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.html},
	shorttitle = {The Devil Is in the Details},
	eventtitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	pages = {17492--17501},
	author = {Zou, Renjie and Song, Chunfeng and Zhang, Zhaoxiang},
	urldate = {2022-10-01},
	date = {2022},
	langid = {english},
	keywords = {{RGB}},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CHNFZ8FA\\Zou et al. - 2022 - The Devil Is in the Details Window-Based Attentio.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\HQJ9Z8GI\\Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.html:text/html},
}

@article{hong_spectralformer_2022,
	title = {{SpectralFormer}: Rethinking Hyperspectral Image Classification with Transformers},
	volume = {60},
	issn = {0196-2892, 1558-0644},
	url = {http://arxiv.org/abs/2107.02988},
	doi = {10.1109/TGRS.2021.3130716},
	shorttitle = {{SpectralFormer}},
	abstract = {Hyperspectral ({HS}) images are characterized by approximately contiguous spectral information, enabling the fine identification of materials by capturing subtle spectral discrepancies. Owing to their excellent locally contextual modeling ability, convolutional neural networks ({CNNs}) have been proven to be a powerful feature extractor in {HS} image classification. However, {CNNs} fail to mine and represent the sequence attributes of spectral signatures well due to the limitations of their inherent network backbone. To solve this issue, we rethink {HS} image classification from a sequential perspective with transformers, and propose a novel backbone network called {\textbackslash}ul\{{SpectralFormer}\}. Beyond band-wise representations in classic transformers, {SpectralFormer} is capable of learning spectrally local sequence information from neighboring bands of {HS} images, yielding group-wise spectral embeddings. More significantly, to reduce the possibility of losing valuable information in the layer-wise propagation process, we devise a cross-layer skip connection to convey memory-like components from shallow to deep layers by adaptively learning to fuse "soft" residuals across layers. It is worth noting that the proposed {SpectralFormer} is a highly flexible backbone network, which can be applicable to both pixel- and patch-wise inputs. We evaluate the classification performance of the proposed {SpectralFormer} on three {HS} datasets by conducting extensive experiments, showing the superiority over classic transformers and achieving a significant improvement in comparison with state-of-the-art backbone networks. The codes of this work will be available at https://github.com/danfenghong/{IEEE}\_TGRS\_SpectralFormer for the sake of reproducibility.},
	pages = {1--15},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	shortjournal = {{IEEE} Trans. Geosci. Remote Sensing},
	author = {Hong, Danfeng and Han, Zhu and Yao, Jing and Gao, Lianru and Zhang, Bing and Plaza, Antonio and Chanussot, Jocelyn},
	urldate = {2022-10-01},
	date = {2022},
	eprinttype = {arxiv},
	eprint = {2107.02988 [cs]},
	keywords = {Hyperspectral, Computer Science - Computer Vision and Pattern Recognition, Transformer, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\22H8XK7D\\Hong et al. - 2022 - SpectralFormer Rethinking Hyperspectral Image Cla.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\NFISRMRG\\2107.html:text/html},
}

@article{he_spatial-spectral_2021,
	title = {Spatial-Spectral Transformer for Hyperspectral Image Classification},
	volume = {13},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/3/498},
	doi = {10.3390/rs13030498},
	abstract = {Recently, a great many deep convolutional neural network ({CNN})-based methods have been proposed for hyperspectral image ({HSI}) classification. Although the proposed {CNN}-based methods have the advantages of spatial feature extraction, they are difficult to handle the sequential data with and {CNNs} are not good at modeling the long-range dependencies. However, the spectra of {HSI} are a kind of sequential data, and {HSI} usually contains hundreds of bands. Therefore, it is difficult for {CNNs} to handle {HSI} processing well. On the other hand, the Transformer model, which is based on an attention mechanism, has proved its advantages in processing sequential data. To address the issue of capturing relationships of sequential spectra in {HSI} in a long distance, in this study, Transformer is investigated for {HSI} classification. Specifically, in this study, a new classification framework titled spatial-spectral Transformer ({SST}) is proposed for {HSI} classification. In the proposed {SST}, a well-designed {CNN} is used to extract the spatial features, and a modified Transformer (a Transformer with dense connection, i.e., {DenseTransformer}) is proposed to capture sequential spectra relationships, and multilayer perceptron is used to finish the final classification task. Furthermore, dynamic feature augmentation, which aims to alleviate the overfitting problem and therefore generalize the model well, is proposed and added to the {SST} ({SST}-{FA}). In addition, to address the issue of limited training samples in {HSI} classification, transfer learning is combined with {SST}, and another classification framework titled transferring-{SST} (T-{SST}) is proposed. At last, to mitigate the overfitting problem and improve the classification accuracy, label smoothing is introduced for the T-{SST}-based classification framework (T-{SST}-L). The proposed {SST}, {SST}-{FA}, T-{SST}, and T-{SST}-L are tested on three widely used hyperspectral datasets. The obtained results reveal that the proposed models provide competitive results compared to the state-of-the-art methods, which shows that the concept of Transformer opens a new window for {HSI} classification.},
	pages = {498},
	number = {3},
	journaltitle = {Remote Sensing},
	author = {He, Xin and Chen, Yushi and Lin, Zhouhan},
	urldate = {2022-10-01},
	date = {2021-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Hyperspectral, Transformer, classification, convolutional neural network ({CNN}), hyperspectral image ({HSI})},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\MAXP6GXN\\He et al. - 2021 - Spatial-Spectral Transformer for Hyperspectral Ima.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\NASN78XL\\498.html:text/html},
}

@article{guo_learned_2021,
	title = {Learned Hyperspectral Compression Using a Student’s T Hyperprior},
	volume = {13},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/21/4390},
	doi = {10.3390/rs13214390},
	abstract = {Hyperspectral compression is one of the most common techniques in hyperspectral image processing. Most recent learned image compression methods have exhibited excellent rate-distortion performance for natural images, but they have not been fully explored for hyperspectral compression tasks. In this paper, we propose a trainable network architecture for hyperspectral compression tasks, which not only considers the anisotropic characteristic of hyperspectral images but also embeds an accurate entropy model using the non-Gaussian prior knowledge of hyperspectral images and nonlinear transform. Specifically, we first design a spatial-spectral block, involving a spatial net and a spectral net as the base components of the core autoencoder, which is more consistent with the anisotropic hyperspectral cubes than the existing compression methods based on deep learning. Then, we design a Student’s T hyperprior that merges the statistics of the latents and the side information concepts into a unified neural network to provide an accurate entropy model used for entropy coding. This not only remarkably enhances the flexibility of the entropy model by adjusting various values of the degree of freedom, but also leads to a superior rate-distortion performance. The results illustrate that the proposed compression scheme supersedes the Gaussian hyperprior universally for virtually all learned natural image codecs and the optimal linear transform coding methods for hyperspectral compression. Specifically, the proposed method provides a 1.51\% to 59.95\% average increase in peak signal-to-noise ratio, a 0.17\% to 18.17\% average increase in the structural similarity index metric and a 6.15\% to 64.60\% average reduction in spectral angle mapping over three public hyperspectral datasets compared to the Gaussian hyperprior and the optimal linear transform coding methods.},
	pages = {4390},
	number = {21},
	journaltitle = {Remote Sensing},
	author = {Guo, Yuanyuan and Chong, Yanwen and Ding, Yun and Pan, Shaoming and Gu, Xiaolin},
	urldate = {2022-10-01},
	date = {2021-01},
	langid = {english},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Hyperspectral, artificial neural networks, entropy model, hyperspectral compression, student’s T distribution},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\TF97UC2T\\Guo et al. - 2021 - Learned Hyperspectral Compression Using a Student’.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\DRVI6RM7\\4390.html:text/html},
}

@inproceedings{minnen_joint_2018,
	title = {Joint Autoregressive and Hierarchical Priors for Learned Image Compression},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/53edebc543333dfbf7c5933af792c9c4-Abstract.html},
	abstract = {Recent models for learned image compression are based on autoencoders that learn approximately invertible mappings from pixels to a quantized latent representation. The transforms are combined with an entropy model, which is a prior on the latent representation that can be used with standard arithmetic coding algorithms to generate a compressed bitstream. Recently, hierarchical entropy models were introduced as a way to exploit more structure in the latents than previous fully factorized priors, improving compression performance while maintaining end-to-end optimization. Inspired by the success of autoregressive priors in probabilistic generative models, we examine autoregressive, hierarchical, and combined priors as alternatives, weighing their costs and benefits in the context of image compression. While it is well known that autoregressive models can incur a significant computational penalty, we find that in terms of compression performance, autoregressive and hierarchical priors are complementary and can be combined to exploit the probabilistic structure in the latents better than all previous learned models. The combined model yields state-of-the-art rate-distortion performance and generates smaller files than existing methods: 15.8\% rate reductions over the baseline hierarchical model and 59.8\%, 35\%, and 8.4\% savings over {JPEG}, {JPEG}2000, and {BPG}, respectively. To the best of our knowledge, our model is the first learning-based method to outperform the top standard image codec ({BPG}) on both the {PSNR} and {MS}-{SSIM} distortion metrics.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Minnen, David and Ballé, Johannes and Toderici, George D},
	urldate = {2022-10-01},
	date = {2018},
	keywords = {{RGB}, Hierarchical Priors},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\3P92WYEA\\Minnen et al. - 2018 - Joint Autoregressive and Hierarchical Priors for L.pdf:application/pdf},
}

@article{la_grassa_hyperspectral_2022,
	title = {Hyperspectral Data Compression Using Fully Convolutional Autoencoder},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/14/10/2472},
	doi = {10.3390/rs14102472},
	abstract = {In space science and satellite imagery, better resolution of the data information obtained makes images clearer and interpretation more accurate. However, the huge data volume gained by the complex on-board satellite instruments becomes a problem that needs to be managed carefully. To reduce the data volume to be stored and transmitted on-ground, the signals received should be compressed, allowing a good original source representation in the reconstruction step. Image compression covers a key role in space science and satellite imagery and, recently, deep learning models have achieved remarkable results in computer vision. In this paper, we propose a spectral signals compressor network based on deep convolutional autoencoder ({SSCNet}) and we conduct experiments over multi/hyperspectral and {RGB} datasets reporting improvements over all baselines used as benchmarks and than the {JPEG} family algorithm. Experimental results demonstrate the effectiveness in the compression ratio and spectral signal reconstruction and the robustness with a data type greater than 8 bits, clearly exhibiting better results using the {PSNR}, {SSIM}, and {MS}-{SSIM} evaluation criteria.},
	pages = {2472},
	number = {10},
	journaltitle = {Remote Sensing},
	author = {La Grassa, Riccardo and Re, Cristina and Cremonese, Gabriele and Gallo, Ignazio},
	urldate = {2022-10-01},
	date = {2022-01},
	langid = {english},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Hyperspectral, convolutional neural network ({CNN}), autoencoder, data compression, remote sensing, satellite images},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\BFRQTF6U\\La Grassa et al. - 2022 - Hyperspectral Data Compression Using Fully Convolu.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\RFNXFEDG\\htm.html:text/html},
}

@misc{balle_end--end_2017,
	title = {End-to-end Optimized Image Compression},
	url = {http://arxiv.org/abs/1611.01704},
	doi = {10.48550/arXiv.1611.01704},
	abstract = {We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard {JPEG} and {JPEG} 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using {MS}-{SSIM}.},
	number = {{arXiv}:1611.01704},
	publisher = {{arXiv}},
	author = {Ballé, Johannes and Laparra, Valero and Simoncelli, Eero P.},
	urldate = {2022-10-01},
	date = {2017-03-03},
	eprinttype = {arxiv},
	eprint = {1611.01704 [cs, math]},
	note = {Number: {arXiv}:1611.01704},
	keywords = {Computer Science - Information Theory, {RGB}, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\6UR64VEC\\Ballé et al. - 2017 - End-to-end Optimized Image Compression.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\2LTVDF9V\\1611.html:text/html},
}

@inproceedings{kuester_1d-convolutional_2021,
	title = {1d-Convolutional Autoencoder Based Hyperspectral Data Compression},
	rights = {© 2021. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the {ProQuest} Terms and Conditions, you may use this content in accordance with the terms of the License.},
	url = {https://www.proquest.com/docview/2585318626},
	doi = {10.5194/isprs-archives-XLIII-B1-2021-15-2021},
	abstract = {Hyperspectral sensor technology has been advancing in recent years and become more practical to tackle a variety of applications. The arising issues of data transmission and storage can be addressed with the help of compression. To minimize the loss of important information, high spectral correlation between adjacent bands is exploited. In this paper, we introduce an approach to compress hyperspectral data based on a 1D-Convolutional Autoencoder. Compression is achieved through reducing correlation by transforming the spectral signature into a low-dimensional space, while simultaneously preserving the significant features. The focus lies on compression of the spectral dimension. The spatial dimension is not used in the compression in order not to falsify correlation between the spectral dimension and accuracy of the reconstruction. The proposed 1D-Convolutional Autoencoder efficiently finds and extracts features relevant for compression. Additionally, it can be exploited as a feature extractor or for dimensionality reduction. The hyperspectral data sets Greding Village and Pavia University were used for the training and the evaluation process. The reconstruction accuracy is evaluated using the Signal to Noise Ratio and the Spectral Angle. Additionally, a land cover classification using a multi-class Support Vector Machine is used as a target application. The classification performance of the original and reconstructed data are compared. The reconstruction accuracy of the 1D-Convolutional Autoencoder outperforms the Deep Autoencoder and Nonlinear Principal Component Analysis for the used metrics and for both data sets using a fixed compression ratio.},
	pages = {15--21},
	publisher = {Copernicus {GmbH}},
	author = {Kuester, J. 1 and Gross, W. 1 and Middelmann, W. 1 1 Fraunhofer {IOSB} and Image Exploitation, Germany and Fraunhofer {IOSB}, Ettlingen and Image Exploitation, Germany},
	urldate = {2022-10-01},
	date = {2021},
	note = {{ISSN}: 16821750
Num Pages: 15-21},
	keywords = {Hyperspectral, convolutional neural network ({CNN})},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\SU885T65\\Kuester et al. - 2021 - 1d-Convolutional Autoencoder Based Hyperspectral D.pdf:application/pdf},
}

@article{zea_leveraging_2022,
	title = {Leveraging high-throughput hyperspectral imaging technology to detect cadmium stress in two leafy green crops and accelerate soil remediation efforts},
	volume = {292},
	issn = {0269-7491},
	url = {https://www.sciencedirect.com/science/article/pii/S0269749121019874},
	doi = {10.1016/j.envpol.2021.118405},
	abstract = {Cadmium (Cd) is a toxic metal that can accumulate in soils and negatively impact crop as well as human health. Amendments like biochar have potential to address these challenges by reducing Cd bioavailability in soil, though reliance on post-harvest wet chemical methods to quantify Cd uptake have slowed efforts to identify the most effective amendments. Hyperspectral imaging ({HSI}) is a novel technology that could overcome this limitation by quantifying symptoms of Cd stress while plants are still growing. The goals of this study were to: 1) determine whether {HSI} can detect Cd stress in two distinct leafy green crops, 2) quantify whether a locally sourced biochar derived from hardwoods can reduce Cd stress and uptake in these crops, and 3) identify vegetative indices ({VIs}) that best quantify changes in plant stress responses. Experiments were conducted in a tightly controlled automated phenotyping facility that allowed all environmental factors to be kept constant except Cd concentration (0, 5 10 and 15 mg kg−1). Symptoms of Cd stress were stronger in basil (Ocimum basilicum) than kale (Brassica oleracea), and were easier to detect using {HSI}. Several {VIs} detected Cd stress in basil, but only the anthocyanin reflectance index ({ARI}) detected all levels of Cd stress in both crop species. The biochar amendment did reduce Cd uptake, especially at low Cd concentrations in kale which took up more Cd than basil. Again, the {ARI} index was the most effective in quantifying changes in plant stress mediated by the biochar. These results indicate that the biochar evaluated in this study has potential to reduce Cd bioavailability in soil, and {HSI} could be further developed to identify rates that can best achieve this benefit. The technology also may be helping in elucidating mechanisms mediating how biochar can influence plant growth and stress responses.},
	pages = {118405},
	journaltitle = {Environmental Pollution},
	shortjournal = {Environmental Pollution},
	author = {Zea, Maria and Souza, Augusto and Yang, Yang and Lee, Linda and Nemali, Krishna and Hoagland, Lori},
	urldate = {2023-04-02},
	date = {2022-01-01},
	langid = {english},
	keywords = {Basil, Biochar, Hormesis, Kale, Plant uptake, Vegetative indices},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\X62SJCS7\\Zea et al. - 2022 - Leveraging high-throughput hyperspectral imaging t.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\YH7GWHK7\\S0269749121019874.html:text/html},
}

@article{henriksen_plastic_2022,
	title = {Plastic classification via in-line hyperspectral camera analysis and unsupervised machine learning},
	volume = {118},
	issn = {0924-2031},
	url = {https://www.sciencedirect.com/science/article/pii/S0924203121001247},
	doi = {10.1016/j.vibspec.2021.103329},
	abstract = {An increase in the quality of recycled plastic is paramount to address the global plastic challenge and applicability of recycled plastics. A potent approach is mechanical plastic sorting but sufficient analytical techniques are needed. This study applies unsupervised machine learning on short wave infrared hyperspectral data to build a model for classification of plastics. The model can successfully distinguish between twelve plastics ({PE}, {PP}, {PET}, {PS}, {PVC}, {PVDF}, {POM}, {PEEK}, {ABS}, {PMMA}, {PC}, and {PA}12) and the utility is further proven by recognizing three unknown samples ({PS}, {PMMA}, {PC}). The experimental setup is constructed similar to an in-line industrial setup, and the machine learning is optimized for minimal data processing. This ensures the industrial relevance and is a stepping-stone to solve the global plastic challenge.},
	pages = {103329},
	journaltitle = {Vibrational Spectroscopy},
	shortjournal = {Vibrational Spectroscopy},
	author = {Henriksen, Martin L. and Karlsen, Celine B. and Klarskov, Pernille and Hinge, Mogens},
	urldate = {2023-04-02},
	date = {2022-01-01},
	langid = {english},
	keywords = {Principal component analysis, Hyperspectral imaging, Plastic identification, Plastic recycling},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\STCNXW5X\\Henriksen et al. - 2022 - Plastic classification via in-line hyperspectral c.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\8LFXQHQU\\S0924203121001247.html:text/html},
}

@article{guanter_enmap_2015,
	title = {The {EnMAP} Spaceborne Imaging Spectroscopy Mission for Earth Observation},
	volume = {7},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/7/7/8830},
	doi = {10.3390/rs70708830},
	abstract = {Imaging spectroscopy, also known as hyperspectral remote sensing, is based on the characterization of Earth surface materials and processes through spectrally-resolved measurements of the light interacting with matter. The potential of imaging spectroscopy for Earth remote sensing has been demonstrated since the 1980s. However, most of the developments and applications in imaging spectroscopy have largely relied on airborne spectrometers, as the amount and quality of space-based imaging spectroscopy data remain relatively low to date. The upcoming Environmental Mapping and Analysis Program ({EnMAP}) German imaging spectroscopy mission is intended to fill this gap. An overview of the main characteristics and current status of the mission is provided in this contribution. The core payload of {EnMAP} consists of a dual-spectrometer instrument measuring in the optical spectral range between 420 and 2450 nm with a spectral sampling distance varying between 5 and 12 nm and a reference signal-to-noise ratio of 400:1 in the visible and near-infrared and 180:1 in the shortwave-infrared parts of the spectrum. {EnMAP} images will cover a 30 km-wide area in the across-track direction with a ground sampling distance of 30 m. An across-track tilted observation capability will enable a target revisit time of up to four days at the Equator and better at high latitudes. {EnMAP} will contribute to the development and exploitation of spaceborne imaging spectroscopy applications by making high-quality data freely available to scientific users worldwide.},
	pages = {8830--8857},
	number = {7},
	journaltitle = {Remote Sensing},
	author = {Guanter, Luis and Kaufmann, Hermann and Segl, Karl and Foerster, Saskia and Rogass, Christian and Chabrillat, Sabine and Kuester, Theres and Hollstein, André and Rossner, Godela and Chlebek, Christian and Straif, Christoph and Fischer, Sebastian and Schrader, Stefanie and Storch, Tobias and Heiden, Uta and Mueller, Andreas and Bachmann, Martin and Mühle, Helmut and Müller, Rupert and Habermeyer, Martin and Ohndorf, Andreas and Hill, Joachim and Buddenbaum, Henning and Hostert, Patrick and Van der Linden, Sebastian and Leitão, Pedro J. and Rabe, Andreas and Doerffer, Roland and Krasemann, Hajo and Xi, Hongyan and Mauser, Wolfram and Hank, Tobias and Locherer, Matthias and Rast, Michael and Staenz, Karl and Sang, Bernhard},
	urldate = {2023-04-02},
	date = {2015-07},
	langid = {english},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Earth observation, {EnMAP}, environmental applications, hyperspectral remote sensing, imaging spectroscopy},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\ZX7JQPUP\\Guanter et al. - 2015 - The EnMAP Spaceborne Imaging Spectroscopy Mission .pdf:application/pdf},
}

@article{pascual-venteo_prototyping_2022,
	title = {Prototyping Crop Traits Retrieval Models for {CHIME}: Dimensionality Reduction Strategies Applied to {PRISMA} Data},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/14/10/2448},
	doi = {10.3390/rs14102448},
	shorttitle = {Prototyping Crop Traits Retrieval Models for {CHIME}},
	abstract = {In preparation for new-generation imaging spectrometer missions and the accompanying unprecedented inflow of hyperspectral data, optimized models are needed to generate vegetation traits routinely. Hybrid models, combining radiative transfer models with machine learning algorithms, are preferred, however, dealing with spectral collinearity imposes an additional challenge. In this study, we analyzed two spectral dimensionality reduction methods: principal component analysis ({PCA}) and band ranking ({BR}), embedded in a hybrid workflow for the retrieval of specific leaf area ({SLA}), leaf area index ({LAI}), canopy water content ({CWC}), canopy chlorophyll content ({CCC}), the fraction of absorbed photosynthetic active radiation ({FAPAR}), and fractional vegetation cover ({FVC}). The {SCOPE} model was used to simulate training data sets, which were optimized with active learning. Gaussian process regression ({GPR}) algorithms were trained over the simulations to obtain trait-specific models. The inclusion of {PCA} and {BR} with 20 features led to the so-called {GPR}-20PCA and {GPR}-20BR models. The 20PCA models encompassed over 99.95\% cumulative variance of the full spectral data, while the {GPR}-20BR models were based on the 20 most sensitive bands. Validation against in situ data obtained moderate to optimal results with normalized root mean squared error ({NRMSE}) from 13.9\% ({CWC}) to 22.3\% ({CCC}) for {GPR}-20PCA models, and {NRMSE} from 19.6\% ({CWC}) to 29.1\% ({SLA}) for {GPR}-20BR models. Overall, the {GPR}-20PCA slightly outperformed the {GPR}-20BR models for all six variables. To demonstrate mapping capabilities, both models were tested on a {PRecursore} {IperSpettrale} della Missione Applicativa ({PRISMA}) scene, spectrally resampled to Copernicus Hyperspectral Imaging Mission for the Environment ({CHIME}), over an agricultural test site (Jolanda di Savoia, Italy). The two strategies obtained plausible spatial patterns, and consistency between the two models was highest for {FVC} and {LAI} (R2=0.91, R2=0.86) and lowest for {SLA} mapping (R2=0.53). From these findings, we recommend implementing {GPR}-20PCA models as the most efficient strategy for the retrieval of multiple crop traits from hyperspectral data streams. Hence, this workflow will support and facilitate the preparations of traits retrieval models from the next-generation operational {CHIME}.},
	pages = {2448},
	number = {10},
	journaltitle = {Remote Sensing},
	author = {Pascual-Venteo, Ana B. and Portalés, Enrique and Berger, Katja and Tagliabue, Giulia and Garcia, Jose L. and Pérez-Suay, Adrián and Rivera-Caicedo, Juan Pablo and Verrelst, Jochem},
	urldate = {2023-04-02},
	date = {2022-01},
	langid = {english},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {active learning, biochemical and biophysical traits, {CHIME}, feature selection, Gaussian process regression, hybrid methods, principal component analysis, {PRISMA}},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\8LYL493V\\Pascual-Venteo et al. - 2022 - Prototyping Crop Traits Retrieval Models for CHIME.pdf:application/pdf},
}

@article{dopper_estimating_2022,
	title = {Estimating soil moisture content under grassland with hyperspectral data using radiative transfer modelling and machine learning},
	volume = {110},
	issn = {1569-8432},
	url = {https://www.sciencedirect.com/science/article/pii/S156984322200019X},
	doi = {10.1016/j.jag.2022.102817},
	abstract = {The monitoring of soil moisture content ({SMC}) at very high spatial resolution ({\textless}10m) using unmanned aerial systems ({UAS}) is of high interest for precision agriculture and the validation of large scale {SMC} products. Data-driven approaches are the most common method to retrieve {SMC} with {UAS}-borne data at water limited sites over non-disturbed agricultural crops. A major disadvantage of data-driven algorithms is the limited transferability in space and time and the need of a high number of ground reference samples. Physically-based approaches are less dependent on the amount of samples and are transferable in space and time. This study explores the potential of (1) a hybrid method targeting the soil brightness factor of the {PROSAIL} model using a variational heteroscedastic Gaussian Processes regression ({VHGPR}) algorithm, and (2) a data-driven method employing {VHGPR} for the retrieval of {SMC} over three grassland sites based on {UAS}-borne {VIS}–{NIR} (399–1001nm) hyperspectral data. The sites were managed by mowing (Fendt), grazing (Grosses Bruch) and irrigation (Marquardt). With these distinct local pre-conditions we aimed to identify factors that favor and limit the retrieval of {SMC}. The hybrid approach presented encouraging results in Marquardt ({RMSE} = 1.5Vol\_\%, R2 = 0.2). At the permanent grassland sites (Fendt, Grosses Bruch) the thatch layer jeopardized the application of the hybrid model. We identified the complex canopy structure of grassland as the main factor impacting the hybrid {SMC} retrieval. The data-driven approach showed high accuracy for Fendt (R2 = 0.84, {RMSE} = 8.66) and Marquardt (R2 = 0.4, {RMSE} = 10.52). All data-driven models build on the {LAI}-{SMC} relationship. However, this relationship was hampered by mowing (Fendt), leading to a lack of transferability in time. The alteration of plant traits by grazing prevents finding a relationship with {SMC} in Grosses Bruch. In Marquardt, we identified the timelag between changes in {SMC} and plant response as the main reason of decrease in model accuracy. Yet, the model performance is accurate in undisturbed and water-limited areas (Marquardt). The analysis points to challenges that need to be tackled in future research and opens the discussion for the development of robust models to retrieve high resolution {SMC} from {UAS}-borne remote sensing observations.},
	pages = {102817},
	journaltitle = {International Journal of Applied Earth Observation and Geoinformation},
	shortjournal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Döpper, Veronika and Rocha, Alby Duarte and Berger, Katja and Gränzig, Tobias and Verrelst, Jochem and Kleinschmit, Birgit and Förster, Michael},
	urldate = {2023-04-02},
	date = {2022-06-01},
	langid = {english},
	keywords = {Anthropogenic Influence, Gaussian Processes, Grazing, Irrigation, {LAI}, Leaf Area Index, Mowing, {PROSAIL}, Time Lag, Unmanned Aerial Systems},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\3VRYB6K3\\Döpper et al. - 2022 - Estimating soil moisture content under grassland w.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\RQGGM7CR\\S156984322200019X.html:text/html},
}

@article{bohn_glacier_2022,
	title = {Glacier Ice Surface Properties in South-West Greenland Ice Sheet: First Estimates From {PRISMA} Imaging Spectroscopy Data},
	volume = {127},
	issn = {2169-8961},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021JG006718},
	doi = {10.1029/2021JG006718},
	shorttitle = {Glacier Ice Surface Properties in South-West Greenland Ice Sheet},
	abstract = {Snow and ice melt processes on the Greenland Ice Sheet are a key in Earth's energy balance and are acutely sensitive to climate change. Melting dynamics are directly related to a decrease in surface albedo, amongst others caused by the accumulation of light-absorbing particles ({LAPs}). Featuring unique spectral patterns, these accumulations can be mapped and quantified by imaging spectroscopy. We present first results for the retrieval of glacier ice properties from the spaceborne {PRISMA} imaging spectrometer by applying a recently developed simultaneous inversion of atmospheric and surface state using optimal estimation. The image analyzed in this study was acquired over the South-West margin of the Greenland Ice Sheet in late August 2020. The area is characterized by patterns of both clean and dark ice associated with a high amount of {LAPs} deposited on the surface. We present retrieval maps and uncertainties for grain size, liquid water, and algae concentration, as well as estimated reflectance spectra for different surface properties. We then show the feasibility of using imaging spectroscopy to interpret multiband sensor data to achieve high accuracy, frequently repeated observations of changing snow and ice conditions. For example, the impurity index calculated from multiband Sentinel-3 Ocean and Land Colour Instrument measurements is dependent on dust particles, but we show that algae concentration alone can be predicted from this data with less than 20\% uncertainty. Our study evidences that present and upcoming orbital imaging spectroscopy missions such as {PRISMA}, Environmental Mapping and Analysis Program, Copernicus Hyperspectral Imaging Mission, and the Surface Biology and Geology designated observable, can significantly support research of melting ice sheets.},
	pages = {e2021JG006718},
	number = {3},
	journaltitle = {Journal of Geophysical Research: Biogeosciences},
	author = {Bohn, Niklas and Di Mauro, Biagio and Colombo, Roberto and Thompson, David R. and Susiluoto, Jouni and Carmon, Nimrod and Turmon, Michael J. and Guanter, Luis},
	urldate = {2023-04-02},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2021JG006718},
	keywords = {imaging spectroscopy, {PRISMA}, Greenland Ice Sheet, mapping glacier algae, optimal estimation, snow and ice surface properties},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CDTGX9TP\\Bohn et al. - 2022 - Glacier Ice Surface Properties in South-West Green.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\SCAA9U65\\2021JG006718.html:text/html},
}

@inproceedings{aidini_hyperspectral_2019,
	location = {Pacific Grove, {CA}, {USA}},
	title = {Hyperspectral Image Compression and Super-Resolution Using Tensor Decomposition Learning},
	isbn = {978-1-72814-300-2},
	url = {https://ieeexplore.ieee.org/document/9048735/},
	doi = {10.1109/IEEECONF44664.2019.9048735},
	abstract = {As the ﬁeld of remote sensing for Earth Observation is rapidly evolving, there is an increasing demand for developing suitable methods to store and transmit the massive amounts of the generated data. At the same time, as multiple sensors acquire observations with different dimensions, super-resolution methods come into play to unify the framework for upcoming statistical inference tasks. In this paper, we employ a tensorbased structuring of multi-spectral image data and we propose a low-rank tensor completion scheme for efﬁcient image-content compression and recovery. To address the problem of lowresolution imagery, we further provide a robust algorithmic scheme for super-resolving satellite images, followed by a stateof-the-art convolutional neural network architecture serving the classiﬁcation task of the employed images. Experimental analysis on real-world observations demonstrates the detrimental effects of image compression on classiﬁcation, an issued successfully addressed by the proposed recovery and super-resolution schemes.},
	eventtitle = {2019 53rd Asilomar Conference on Signals, Systems, and Computers},
	pages = {1369--1373},
	booktitle = {2019 53rd Asilomar Conference on Signals, Systems, and Computers},
	publisher = {{IEEE}},
	author = {Aidini, A. and Giannopoulos, M. and Pentari, A. and Fotiadou, K. and Tsakalides, P.},
	urldate = {2023-04-10},
	date = {2019-11},
	langid = {english},
	file = {Aidini et al. - 2019 - Hyperspectral Image Compression and Super-Resoluti.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\N8B858V8\\Aidini et al. - 2019 - Hyperspectral Image Compression and Super-Resoluti.pdf:application/pdf},
}

@article{luo_lossless_2019,
	title = {Lossless compression for hyperspectral image using deep recurrent neural networks},
	volume = {10},
	issn = {1868-808X},
	url = {https://doi.org/10.1007/s13042-019-00937-2},
	doi = {10.1007/s13042-019-00937-2},
	abstract = {With the rapid development of hyperspectral remote sensing technology, the spatial resolution and spectral resolution of hyperspectral images are continually increasing, resulting in a continual increase in the scale of hyperspectral data. At present, hyperspectral lossless compression technology has reached a bottleneck. Simultaneously, the rise of deep learning has provided us with new ideas. Therefore, this paper examines the use of deep learning for the lossless compression of hyperspectral images. In view of the differential pulse code modulation ({DPCM}) method being insufficient for predicting spectral band information, the proposed method, called C-{DPCM}-{RNN}, uses a deep recurrent neural network ({RNN}) to improve the traditional {DPCM} method and improve the generalization ability and prediction accuracy of the model. The final experimental result shows that C-{DPCM}-{RNN} achieves better compression on a set of calibrated {AVIRIS} test images provided by the Multispectral and Hyperspectral Data Compression Working Group of the Consultative Committee for Space Data Systems in 2006. C-{DPCM}-{RNN} overcomes the limits of traditional methods in its performance on uncalibrated {AVIRIS} test images.},
	pages = {2619--2629},
	number = {10},
	journaltitle = {International Journal of Machine Learning and Cybernetics},
	shortjournal = {Int. J. Mach. Learn. \& Cyber.},
	author = {Luo, Jiqiang and Wu, Jiaji and Zhao, Shihui and Wang, Lei and Xu, Tingfa},
	urldate = {2023-04-10},
	date = {2019-10-01},
	langid = {english},
	keywords = {Deep learning, Hyperspectral images, Lossless compression},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\V7A7434K\\Luo et al. - 2019 - Lossless compression for hyperspectral image using.pdf:application/pdf},
}

@article{ulku_large-scale_2018,
	title = {Large-scale hyperspectral image compression via sparse representations based on online learning},
	volume = {28},
	issn = {2083-8492},
	url = {https://www.sciendo.com/article/10.2478/amcs-2018-0015},
	doi = {10.2478/amcs-2018-0015},
	abstract = {In this study, proximity based optimization algorithms are used for lossy compression of hyperspectral images that are inherently large scale. This is the ﬁrst time that such proximity based optimization algorithms are implemented with an online dictionary learning method. Compression performances are compared with the one obtained by various sparse representation algorithms. As a result, proximity based optimization algorithms are listed among the three best ones in terms of compression performance values for all hyperspectral images. Additionally, the applicability of anomaly detection is tested on the reconstructed images.},
	pages = {197--207},
	number = {1},
	journaltitle = {International Journal of Applied Mathematics and Computer Science},
	author = {Ülkü, İrem and Kizgut, Ersin},
	urldate = {2023-04-10},
	date = {2018-03-01},
	langid = {english},
	file = {Ülkü und Kizgut - 2018 - Large-scale hyperspectral image compression via sp.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\UMRA6TII\\Ülkü und Kizgut - 2018 - Large-scale hyperspectral image compression via sp.pdf:application/pdf},
}

@incollection{leal-taixe_onboard_2019,
	location = {Cham},
	title = {Onboard Hyperspectral Image Compression Using Compressed Sensing and Deep Learning},
	volume = {11130},
	isbn = {978-3-030-11011-6 978-3-030-11012-3},
	url = {https://link.springer.com/10.1007/978-3-030-11012-3_3},
	abstract = {We propose a real-time onboard compression scheme for hyperspectral datacube which consists of a very low complexity encoder and a deep learning based parallel decoder architecture for fast decompression. The encoder creates a set of coded snapshots from a given datacube using a measurement code matrix. The decoder decompresses the coded snapshots by using a sparse recovery algorithm. We solve this sparse recovery problem using a deep neural network for fast reconstruction. We present experimental results which demonstrate that our technique performs very well in terms of quality of reconstruction and in terms of computational requirements compared to other transform based techniques with some tradeoﬀ in {PSNR}. The proposed technique also enables faster inference in compressed domain, suitable for on-board requirements.},
	pages = {30--42},
	booktitle = {Computer Vision – {ECCV} 2018 Workshops},
	publisher = {Springer International Publishing},
	author = {Kumar, Saurabh and Chaudhuri, Subhasis and Banerjee, Biplab and Ali, Feroz},
	editor = {Leal-Taixé, Laura and Roth, Stefan},
	urldate = {2023-04-10},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-11012-3_3},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Kumar et al. - 2019 - Onboard Hyperspectral Image Compression Using Comp.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\GYBTPNQN\\Kumar et al. - 2019 - Onboard Hyperspectral Image Compression Using Comp.pdf:application/pdf},
}

@inproceedings{shen_golomb-rice_2017,
	location = {Fort Worth, {TX}},
	title = {Golomb-Rice coding parameter learning using deep belief network for hyperspectral image compression},
	isbn = {978-1-5090-4951-6},
	url = {http://ieeexplore.ieee.org/document/8127434/},
	doi = {10.1109/IGARSS.2017.8127434},
	abstract = {While Golomb-Rice codes are optimal for geometrically distributed source, the practically achievable coding efﬁciency depends on the accuracy of the coding parameter estimated from the input data. Most existing methods are based on the assumption of geometric distribution and thus would suffer from a loss in coding efﬁciency if the underlying distribution deviates from the geometric distribution, which is usually the case in practice. We proposed a data-driven parameter estimation method without assuming the underlying distribution. We formulated the problem of choosing the best coding parameter for the given input data as a pattern classiﬁcation problem. To this end, we trained a deep belief network using the data segments to be coded, along with their “labels”, which are the optimal coding parameters that yield the shortest codewords. Simulations on data synthesized using statistical models, as well as data in hyperspectral image coding showed that the proposed deep learning method tended to be more robust than several state-of-the-art parameter estimation methods, with the capability to further improve the accuracies of these methods.},
	eventtitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})},
	pages = {2239--2242},
	booktitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})},
	publisher = {{IEEE}},
	author = {Shen, Hongda and Pan, W. David and Dong, Yuhang and Jiang, Zhuocheng},
	urldate = {2023-04-10},
	date = {2017-07},
	langid = {english},
	file = {Shen et al. - 2017 - Golomb-Rice coding parameter learning using deep b.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\8LGKWP44\\Shen et al. - 2017 - Golomb-Rice coding parameter learning using deep b.pdf:application/pdf},
}

@article{deng_learning-based_2020,
	title = {Learning-Based Hyperspectral Imagery Compression through Generative Neural Networks},
	volume = {12},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/12/21/3657},
	doi = {10.3390/rs12213657},
	abstract = {Hyperspectral images ({HSIs}), which obtain abundant spectral information for narrow spectral bands (no wider than 10 nm), have greatly improved our ability to qualitatively and quantitatively sense the Earth. Since {HSIs} are collected by high-resolution instruments over a very large number of wavelengths, the data generated by such sensors is enormous, and the amount of data continues to grow, {HSI} compression technique will play more crucial role in this trend. The classical method for {HSI} compression is through compression and reconstruction methods such as three-dimensional wavelet-based techniques or the principle component analysis ({PCA}) transform. In this paper, we provide an alternative approach for {HSI} compression via a generative neural network ({GNN}), which learns the probability distribution of the real data from a random latent code. This is achieved by defining a family of densities and finding the one minimizing the distance between this family and the real data distribution. Then, the well-trained neural network is a representation of the {HSI}, and the compression ratio is determined by the complexity of the {GNN}. Moreover, the latent code can be encrypted by embedding a digit with a random distribution, which makes the code confidential. Experimental examples are presented to demonstrate the potential of the {GNN} to solve image compression problems in the field of {HSI}. Compared with other algorithms, it has better performance at high compression ratio, and there is still much room left for improvements along with the fast development of deep-learning techniques.},
	pages = {3657},
	number = {21},
	journaltitle = {Remote Sensing},
	author = {Deng, Chubo and Cen, Yi and Zhang, Lifu},
	urldate = {2023-04-10},
	date = {2020-01},
	langid = {english},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {compression sensing, feature reduction, generative neural network, hyperspectral},
	file = {Volltext:C\:\\Users\\Niklas\\Zotero\\storage\\QDMBVYLW\\Deng et al. - 2020 - Learning-Based Hyperspectral Imagery Compression t.pdf:application/pdf},
}

@article{hu_coarse--fine_2020,
	title = {Coarse-to-Fine Hyper-Prior Modeling for Learned Image Compression},
	volume = {34},
	rights = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/6736},
	doi = {10.1609/aaai.v34i07.6736},
	abstract = {Approaches to image compression with machine learning now achieve superior performance on the compression rate compared to existing hybrid codecs. The conventional learning-based methods for image compression exploits hyper-prior and spatial context model to facilitate probability estimations. Such models have limitations in modeling long-term dependency and do not fully squeeze out the spatial redundancy in images. In this paper, we propose a coarse-to-fine framework with hierarchical layers of hyper-priors to conduct comprehensive analysis of the image and more effectively reduce spatial redundancy, which improves the rate-distortion performance of image compression significantly. Signal Preserving Hyper Transforms are designed to achieve an in-depth analysis of the latent representation and the Information Aggregation Reconstruction sub-network is proposed to maximally utilize side-information for reconstruction. Experimental results show the effectiveness of the proposed network to efficiently reduce the redundancies in images and improve the rate-distortion performance, especially for high-resolution images. Our project is publicly available at https://huzi96.github.io/coarse-to-fine-compression.html.},
	pages = {11013--11020},
	number = {7},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Hu, Yueyu and Yang, Wenhan and Liu, Jiaying},
	urldate = {2023-04-10},
	date = {2020-04-03},
	langid = {english},
	note = {Number: 07},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\76C5MKLF\\Hu et al. - 2020 - Coarse-to-Fine Hyper-Prior Modeling for Learned Im.pdf:application/pdf},
}

@misc{theis_lossy_2022,
	title = {Lossy Compression with Gaussian Diffusion},
	url = {http://arxiv.org/abs/2206.08889},
	abstract = {We consider a novel lossy compression approach based on unconditional diffusion generative models, which we call {DiffC}. Unlike modern compression schemes which rely on transform coding and quantization to restrict the transmitted information, {DiffC} relies on the efﬁcient communication of pixels corrupted by Gaussian noise. We implement a proof of concept and ﬁnd that it works surprisingly well despite the lack of an encoder transform, outperforming the state-of-the-art generative compression method {HiFiC} on {ImageNet} 64x64. {DiffC} only uses a single model to encode and denoise corrupted pixels at arbitrary bitrates. The approach further provides support for progressive coding, that is, decoding from partial bit streams. We perform a rate-distortion analysis to gain a deeper understanding of its performance, providing analytical results for multivariate Gaussian data as well as theoretic bounds for general distributions. Furthermore, we prove that a ﬂow-based reconstruction achieves a 3 {dB} gain over ancestral sampling at high bitrates.},
	number = {{arXiv}:2206.08889},
	publisher = {{arXiv}},
	author = {Theis, Lucas and Salimans, Tim and Hoffman, Matthew D. and Mentzer, Fabian},
	urldate = {2023-04-10},
	date = {2022-12-31},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2206.08889 [cs, math, stat]},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Theis et al. - 2022 - Lossy Compression with Gaussian Diffusion.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\RPP5J74J\\Theis et al. - 2022 - Lossy Compression with Gaussian Diffusion.pdf:application/pdf},
}

@article{dua_comprehensive_2020,
	title = {Comprehensive review of hyperspectral image compression algorithms},
	volume = {59},
	issn = {0091-3286, 1560-2303},
	url = {https://www.spiedigitallibrary.org/journals/optical-engineering/volume-59/issue-9/090902/Comprehensive-review-of-hyperspectral-image-compression-algorithms/10.1117/1.OE.59.9.090902.full},
	doi = {10.1117/1.OE.59.9.090902},
	abstract = {Rapid advancement in the development of hyperspectral image analysis techniques has led to specialized hyperspectral missions. It results in the bulk transmission of hyperspectral images from sensors to analysis centers and finally to data centers. Storage of these large size images is a critical issue that is handled by compression techniques. This survey focuses on different hyperspectral image compression algorithms that have been classified into two broad categories based on eight internal and six external parameters. In addition, we identified research challenges and suggested future scope for each technique. The detailed classification used in this paper can categorize other compression algorithms and may help in selecting research objectives.},
	pages = {090902},
	number = {9},
	journaltitle = {Optical Engineering},
	shortjournal = {{OE}},
	author = {Dua, Yaman and Kumar, Vinod and Singh, Ravi Shankar},
	urldate = {2023-04-10},
	date = {2020-09},
	note = {Publisher: {SPIE}},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CJZKBW8B\\Dua et al. - 2020 - Comprehensive review of hyperspectral image compre.pdf:application/pdf},
}

@article{blau_rethinking_nodate,
	title = {Rethinking Lossy Compression: The Rate-Distortion-Perception Tradeoff},
	abstract = {Lossy compression algorithms are typically designed and analyzed through the lens of Shannon’s rate-distortion theory, where the goal is to achieve the lowest possible distortion (e.g., low {MSE} or high {SSIM}) at any given bit rate. However, in recent years, it has become increasingly accepted that “low distortion” is not a synonym for “high perceptual quality”, and in fact optimization of one often comes at the expense of the other. In light of this understanding, it is natural to seek for a generalization of rate-distortion theory which takes perceptual quality into account. In this paper, we adopt the mathematical deﬁnition of perceptual quality recently proposed by Blau \& Michaeli (2018), and use it to study the three-way tradeoff between rate, distortion, and perception. We show that restricting the perceptual quality to be high, generally leads to an elevation of the rate-distortion curve, thus necessitating a sacriﬁce in either rate or distortion. We prove several fundamental properties of this triple-tradeoff, calculate it in closed form for a Bernoulli source, and illustrate it visually on a toy {MNIST} example.},
	author = {Blau, Yochai and Michaeli, Tomer},
	langid = {english},
	file = {Blau und Michaeli - Rethinking Lossy Compression The Rate-Distortion-.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\4RZK78N4\\Blau und Michaeli - Rethinking Lossy Compression The Rate-Distortion-.pdf:application/pdf},
}

@incollection{berger_rate-distortion_2003,
	title = {Rate-Distortion Theory},
	isbn = {978-0-471-21928-6},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471219282.eot142},
	abstract = {Rate-distortion theory is the branch of information theory that treats compressing the data produced by an information source down to a specified encoding rate that is strictly less than the source's entropy. This necessarily entails some lossiness, or distortion, between the original source data and the best approximation thereto that can be produced on the basis of the encoder's output bits. Rate-distortion theory was introduced in the seminal works written in 1948 and 1959 by C. E. Shannon, the founder of information theory. We describe Shannon's contribution and then trace its subsequent development worldwide. Heavier than usual emphasis is placed on the concept of “matching” a channel to a source in the rate-distortion sense, and also on the analogous matching of a source to a channel. Experimental evidence has been mounting in support of the hypothesis that living organisms often simultaneously achieve both of these matchings when processing their sensory inputs, thereby eliminating the need for the complex encoding and decoding operations that are needed in order to produce an information-theoretically optimum system in the absence of such double matching.},
	booktitle = {Wiley Encyclopedia of Telecommunications},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Berger, Toby},
	urldate = {2023-04-10},
	date = {2003},
	langid = {english},
	doi = {10.1002/0471219282.eot142},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471219282.eot142},
	keywords = {bioinformation theory, distortion measure, joint source-channel coding, lossy source coding, rate-distortion, Shannon},
	file = {Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\3C25BMXI\\0471219282.html:text/html},
}

@article{zikiou_support_2020,
	title = {Support vector regression-based 3D-wavelet texture learning for hyperspectral image compression},
	volume = {36},
	issn = {0178-2789, 1432-2315},
	url = {http://link.springer.com/10.1007/s00371-019-01753-z},
	doi = {10.1007/s00371-019-01753-z},
	pages = {1473--1490},
	number = {7},
	journaltitle = {The Visual Computer},
	shortjournal = {Vis Comput},
	author = {Zikiou, Nadia and Lahdir, Mourad and Helbert, David},
	urldate = {2023-04-10},
	date = {2020-07},
	langid = {english},
	file = {Zikiou et al. - 2020 - Support vector regression-based 3D-wavelet texture.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\K5GMSX8N\\Zikiou et al. - 2020 - Support vector regression-based 3D-wavelet texture.pdf:application/pdf},
}

@misc{cheng_learned_2020,
	title = {Learned Image Compression with Discretized Gaussian Mixture Likelihoods and Attention Modules},
	url = {http://arxiv.org/abs/2001.01568},
	doi = {10.48550/arXiv.2001.01568},
	abstract = {Image compression is a fundamental research field and many well-known compression standards have been developed for many decades. Recently, learned compression methods exhibit a fast development trend with promising results. However, there is still a performance gap between learned compression algorithms and reigning compression standards, especially in terms of widely used {PSNR} metric. In this paper, we explore the remaining redundancy of recent learned compression algorithms. We have found accurate entropy models for rate estimation largely affect the optimization of network parameters and thus affect the rate-distortion performance. Therefore, in this paper, we propose to use discretized Gaussian Mixture Likelihoods to parameterize the distributions of latent codes, which can achieve a more accurate and flexible entropy model. Besides, we take advantage of recent attention modules and incorporate them into network architecture to enhance the performance. Experimental results demonstrate our proposed method achieves a state-of-the-art performance compared to existing learned compression methods on both Kodak and high-resolution datasets. To our knowledge our approach is the first work to achieve comparable performance with latest compression standard Versatile Video Coding ({VVC}) regarding {PSNR}. More importantly, our approach generates more visually pleasant results when optimized by {MS}-{SSIM}. This project page is at this https {URL} https://github.com/{ZhengxueCheng}/Learned-Image-Compression-with-{GMM}-and-Attention},
	number = {{arXiv}:2001.01568},
	publisher = {{arXiv}},
	author = {Cheng, Zhengxue and Sun, Heming and Takeuchi, Masaru and Katto, Jiro},
	urldate = {2023-04-16},
	date = {2020-03-30},
	eprinttype = {arxiv},
	eprint = {2001.01568 [eess]},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\7NUF688E\\Cheng et al. - 2020 - Learned Image Compression with Discretized Gaussia.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\R6EICM8U\\2001.html:text/html},
}

@article{wainwright_scale_1999,
	title = {Scale Mixtures of Gaussians and the Statistics of Natural Images},
	abstract = {The statistics of photographic images, when represented using multiscale (wavelet) bases, exhibit two striking types of {nonGaussian} behavior. First, the marginal densities of the coefficients have extended heavy tails. Second, the joint densities exhibit variance dependencies not captured by second-order models. We examine properties of the class of Gaussian scale mixtures, and show that these densities can accurately characterize both the marginal and joint distributions of natural image wavelet coefficients. This class of model suggests a Markov structure, in which wavelet coefficients are linked by hidden scaling variables corresponding to local image structure. We derive an estimator for these hidden variables, and show that a nonlinear "normalization" procedure can be used to Gaussianize the coefficients.},
	author = {Wainwright, Martin J and Simoncelli, Eero P},
	date = {1999},
	langid = {english},
	file = {Wainwright und Simoncelli - Scale Mixtures of Gaussians and the Statistics of .pdf:C\:\\Users\\Niklas\\Zotero\\storage\\6Q2NWKWN\\Wainwright und Simoncelli - Scale Mixtures of Gaussians and the Statistics of .pdf:application/pdf},
}

@article{shannon_mathematical_1948,
	title = {A Mathematical Theory of Communication},
	volume = {27},
	issn = {1538-7305},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/j.1538-7305.1948.tb01338.x},
	doi = {10.1002/j.1538-7305.1948.tb01338.x},
	pages = {379--423},
	number = {3},
	journaltitle = {Bell System Technical Journal},
	author = {Shannon, C. E.},
	urldate = {2023-05-02},
	date = {1948},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\W5NIB8BE\\j.1538-7305.1948.tb01338.html:text/html},
}

@book{mackay_information_2003,
	location = {Cambridge, {UK} ; New York},
	title = {Information theory, inference, and learning algorithms},
	isbn = {978-0-521-64298-9},
	pagetotal = {628},
	publisher = {Cambridge University Press},
	author = {{MacKay}, David J. C.},
	date = {2003},
	keywords = {Information theory},
}

@book{cover_elements_2006,
	location = {Hoboken, N.J},
	edition = {2nd ed},
	title = {Elements of information theory},
	isbn = {978-0-471-24195-9},
	pagetotal = {748},
	publisher = {Wiley-Interscience},
	author = {Cover, T. M. and Thomas, Joy A.},
	date = {2006},
	note = {{OCLC}: ocm59879802},
	keywords = {Information theory},
}

@article{garcia-vilchez_impact_2011,
	title = {On the Impact of Lossy Compression on Hyperspectral Image Classification and Unmixing},
	volume = {8},
	issn = {1545-598X, 1558-0571},
	url = {http://ieeexplore.ieee.org/document/5570893/},
	doi = {10.1109/LGRS.2010.2062484},
	abstract = {Hyperspectral data lossy compression has not yet achieved global acceptance in the remote sensing community, mainly because it is generally perceived that using compressed images may affect the results of posterior processing stages. This possible negative effect, however, has not been accurately characterized so far. In this letter, we quantify the impact of lossy compression on two standard approaches for hyperspectral data exploitation: spectral unmixing, and supervised classiﬁcation using support vector machines. Our experimental assessment reveals that different stages of the linear spectral unmixing chain exhibit different sensitivities to lossy data compression. We have also observed that, for certain compression techniques, a higher compression ratio may lead to more accurate classiﬁcation results. Even though these results may seem counterintuitive, this work explains these observations in light of the spatial regularization and/or whitening that most compression techniques perform and further provides recommendations on best practices when applying lossy compression prior to hyperspectral data classiﬁcation and/or unmixing.},
	pages = {253--257},
	number = {2},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Letters},
	shortjournal = {{IEEE} Geosci. Remote Sensing Lett.},
	author = {Garcia-Vilchez, Fernando and Munoz-Mari, Jordi and Zortea, Maciel and Blanes, Ian and Gonzalez-Ruiz, Vicente and Camps-Valls, Gustavo and Plaza, Antonio and Serra-Sagrista, Joan},
	urldate = {2023-05-02},
	date = {2011-03},
	langid = {english},
	file = {Garcia-Vilchez et al. - 2011 - On the Impact of Lossy Compression on Hyperspectra.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\MMXWI7QL\\Garcia-Vilchez et al. - 2011 - On the Impact of Lossy Compression on Hyperspectra.pdf:application/pdf},
}

@inproceedings{guarini_overview_2017,
	title = {Overview of the prisma space and ground segment and its hyperspectral products},
	doi = {10.1109/IGARSS.2017.8126986},
	abstract = {{PRISMA} ({PRecursore} {IperSpettrale} della Missione Applicativa) is an Italian Earth Observation hyperspectral mission, fully funded by the Italian Space Agency ({ASI} - Agenzia Spaziale Italiana) and scheduled for launch in 2018. The {PRISMA} system will be composed of a Space Segment, consisting in a single satellite, embarking a state-of-the-art hyperspectral and panchromatic payload, a Launch Segment in charge of placing the satellite into the appropriate orbit and a Ground Segment geographically distributed in Italy between Fucino and Matera, devoted to satellite/mission control, user management and product delivery. An overview of the main characteristics and current status of the {PRISMA} mission is provided, with a focus on the space and ground segments.},
	eventtitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})},
	pages = {431--434},
	booktitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})},
	author = {Guarini, R. and Loizzo, R. and Longo, F. and Mari, S. and Scopa, T. and Varacalli, G.},
	date = {2017-07},
	note = {{ISSN}: 2153-7003},
	keywords = {{PRISMA}, Calibration, Earth Observation, Ground Segment, Hyperspectral mission, Hyperspectral sensors, Instruments, Orbits, Payloads, Satellites, Space Segment, Space vehicles},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\XCLFNEFC\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\AX3WA8GP\\Guarini et al. - 2017 - Overview of the prisma space and ground segment an.pdf:application/pdf},
}

@inproceedings{guarini_prisma_2018,
	title = {Prisma Hyperspectral Mission Products},
	doi = {10.1109/IGARSS.2018.8517785},
	abstract = {{PRISMA} ({PRecursore} {IperSpettrale} della Missione Applicativa) is an Italian Satellite Earth Observation hyperspectral mission led by the Italian Space Agency ({ASI}) and planned for the launch in 2018. The payload is based on a high spectral resolution imaging spectrometer operating in the {VNIR}/{SWIR} (0.4-2.5 μm) optically integrated with a medium resolution Panchromatic camera (0.4-0.7 μm). The {PRISMA} Ground Segment includes the Mission Control Centre ({MCC}) and the Satellite Control Centre ({SCC}) both located at the Fucino station and the Instrument Data Handling System ({IDHS}) located at the {ASI} Space Geodesy Center in Matera. The {IDHS} is devoted to process the payload data downloaded using the X-Band antenna of the {CNM} (National Multimission Center). The {IDHS} data processing function generates Level 0, Level 1 and Level 2 products archived and distributed by the {CNM}. This paper defines the detailed {PRISMA} product types, specifying the content and process of the products generation.},
	eventtitle = {{IGARSS} 2018 - 2018 {IEEE} International Geoscience and Remote Sensing Symposium},
	pages = {179--182},
	booktitle = {{IGARSS} 2018 - 2018 {IEEE} International Geoscience and Remote Sensing Symposium},
	author = {Guarini, R. and Loizzo, R. and Facchinetti, C. and Longo, F. and Ponticelli, B. and Faraci, M. and Dami, M. and Cosi, M. and Amoruso, L. and De Pasquale, V. and Taggio, N. and Santoro, F. and Colandrea, P. and Miotti, E. and Di Nicolantonio, W.},
	date = {2018-07},
	note = {{ISSN}: 2153-7003},
	keywords = {Hyperspectral imaging, {PRISMA}, hyperspectral, Calibration, Adaptive optics, Clouds, L0 Products, L1 Products, L2 Products, Optical filters, Optical imaging, Validation},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\76UEP49G\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\7GFS2IPB\\Guarini et al. - 2018 - Prisma Hyperspectral Mission Products.pdf:application/pdf},
}

@inproceedings{loizzo_prisma_2019,
	title = {Prisma Mission Status and Perspective},
	doi = {10.1109/IGARSS.2019.8899272},
	abstract = {{PRISMA} ({PRecursore} {IperSpettrale} della Missione Applicativa) is an {ASI} (Italian Space Agency) mission based on a technology demonstrator project, aimed at the in space qualification of an innovative hyperspectral payload and at the development of new Earth Observation products and applications.In the upcoming Earth Observation European scenario {PRISMA} is expected to be a good opportunity for science and users community to access hyperspectral data, both to develop new applications products and to explore technological innovative contribution of hyperspectral data to earth observation, in the perspective of a future hyperspectral operational mission.This paper will report the status of the {PRISMA} mission after the launch was on 22 March 2019 ({VEGA} launcher) and will present the commissioning phase and preliminary mission exploitation plan.},
	eventtitle = {{IGARSS} 2019 - 2019 {IEEE} International Geoscience and Remote Sensing Symposium},
	pages = {4503--4506},
	booktitle = {{IGARSS} 2019 - 2019 {IEEE} International Geoscience and Remote Sensing Symposium},
	author = {Loizzo, R. and Daraio, M. and Guarini, R. and Longo, F. and Lorusso, R. and Dini, L. and Lopinto, E.},
	date = {2019-07},
	note = {{ISSN}: 2153-7003},
	keywords = {Hyperspectral, Hyperspectral imaging, {PRISMA}, Earth Observation, Payloads, Space vehicles, Earth, Image segmentation, Space missions},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\4CJMGEN3\\references.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\ZC4ACIP3\\Loizzo et al. - 2019 - Prisma Mission Status and Perspective.pdf:application/pdf},
}

@article{acito_automatic_2022,
	title = {Automatic Detection and Correction of Defective Pixels in {PRISMA} Hyperspectral Data},
	volume = {60},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2022.3206453},
	abstract = {In satellite hyperspectral sensors, a standard procedure based on homogeneous reference sources is used to regularly update the map of defective pixels ({DPs}). Unfortunately, this procedure often fails to detect some {DPs} both because they may arise in the interval between two standard calibration steps and because they may be characterized by subtle or unexpected signal values. The resulting hyperspectral image is affected by residual nonuniformity noise, which correlates in the along-track direction. This noise source reduces the quality of hyperspectral products, such as classification, unmixing, and material detection. In this article, we present a new procedure to find the location of the residual {DPs} in the detection matrix and we also propose an effective method to estimate the missing radiance values inferring them from the image pixels by leveraging both spatial and spectral correlation. The procedure, here tailored to {PRecursore} {IperSpettrale} della Missione Applicativa ({PRISMA}) hyperspectral images, is quite general and can be easily adapted to process images recorded by any satellite pushbroom hyperspectral sensor. The improved image quality yielded by the proposed procedure is first demonstrated qualitatively, by comparing the global {RX} ({GRX}) maps on the original image with those obtained after detection of the {DPs} and correction of their radiance values. The image quality improvement is then quantified on a set of nine {PRISMA} images, recorded in an interval of about two years, using two ad hoc defined indexes. The analysis is carried out separately for the visible and near-infrared ({VNIR}) and shortwave infrared ({SWIR}) spectrometers of the {PRISMA} mission.},
	pages = {1--15},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	author = {Acito, Nicola and Diani, Marco and Alibani, Michael and Corsini, Giovanni},
	date = {2022},
	note = {Conference Name: {IEEE} Transactions on Geoscience and Remote Sensing},
	keywords = {Hyperspectral imaging, Calibration, Instruments, Defective pixel ({DP}) detection, Detectors, hyperspectral image, {PRecursore} {IperSpettrale} della Missione Applicativa ({PRISMA}), Radiometry, residual nonuniformity, Satellite broadcasting, Standards},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\LIINY3E6\\stamp.html:text/html},
}

@article{acito_prisma_2022,
	title = {{PRISMA} Spatial Resolution Enhancement by Fusion With Sentinel-2 Data},
	volume = {15},
	issn = {2151-1535},
	doi = {10.1109/JSTARS.2021.3132135},
	abstract = {This article deals with the problem of improving the spatial resolution of hyperspectral ({HS}) data from the {PRecursore} {IperSpettrale} della Missione Applicativa ({PRISMA}) mission. For this purpose, higher spatial resolution data from the Sentinel-2 (S2) mission are exploited. Particularly, 10 S2 bands at 10 and 20 m spatial resolution are used to accomplish the {PRISMA} super-resolution ({SR}) task. The article presents a new end-to-end procedure, called {PRISMA}-{SR}, that starting from the S2 data and the low-resolution {PRISMA} image, provides a super-resolved image with a spatial resolution of 10 m and the same spectral resolution as the {PRISMA} {HS} sensor. The first step of the {PRISMA}-{SR} procedure consists in fusing S2 data at different spatial resolutions to obtain a synthetic {MS} image with 10 m spatial resolution and 10 spectral bands. Then, an unsupervised procedure is applied to coregister the fused S2 image and the {PRISMA} image. Finally, the two images at different spatial resolutions are properly combined in order to obtain the super-resolved {HS} image. Solutions for each step of the {PRISMA}-{SR} processing chain are proposed and discussed. Simulated data are used to show the effectiveness of the {PRISMA}-{SR} scheme and to investigate the impact on its performance of each step of the processing chain. Real S2 and {PRISMA} images are finally considered to provide an example of the application of the {PRISMA}-{SR}.},
	pages = {62--79},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Acito, Nicola and Diani, Marco and Corsini, Giovanni},
	date = {2022},
	note = {Conference Name: {IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	keywords = {Hyperspectral imaging, Spatial resolution, Satellites, European Space Agency, Fuses, Hyperspectral ({HS}) data processing, hyperspectral ({HS})-multispectral ({MS}) data fusion, satellite missions, Sensors, Superresolution},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\P3AGVBJT\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\NMGRRGSR\\Acito et al. - 2022 - PRISMA Spatial Resolution Enhancement by Fusion Wi.pdf:application/pdf},
}

@inproceedings{spiller_wildfire_2022,
	title = {Wildfire segmentation analysis from edge computing for on-board real-time alerts using hyperspectral imagery},
	doi = {10.1109/MetroXRAINE54828.2022.9967553},
	abstract = {This paper investigates the opportunity to use artificial intelligence methodologies and edge computing approaches for wildfire detection directly from satellite platforms. The test case for our study is {PRISMA} (Precursore {IperSpettrale} della Missione Applicativa-Hyperspectral Precursor of the Application Mission), the Italian hyperspectral satellite launched in 2019 by the Italian Space Agency. This mission provides hyperspectral ({HS}) images in the spectral range of [0.4,2.5] μm and an average spectral resolution less than 10 nm. This work reports new results related to the Australian bushfires happened in December 2019 in New South Wales, captured by {PRISMA} on December 27, 2019. Starting from a one-dimensional convolutional neural network ({CNN}) discussed in previous authors’ works to perform multiclass classification, this paper primarily deals with the opportunity to use hardware accelerators, namely the Intel Movidius Myriad 2, the Nvidia Jetson {TX}2, and the Nvidia Jetson Nano, to consider the on-the-edge implementation of the {CNN}. This study is in line with the current impulse to improve on-board computing capabilities and platform autonomy, setting some of the elements for future satellites or constellations focusing on specific remote sensing tasks to provide real-time reliable early warnings.},
	eventtitle = {2022 {IEEE} International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering ({MetroXRAINE})},
	pages = {725--730},
	booktitle = {2022 {IEEE} International Conference on Metrology for Extended Reality, Artificial Intelligence and Neural Engineering ({MetroXRAINE})},
	author = {Spiller, Dario and Thangavel, Kathiravan and Sasidharan, Sarathchandrakumar T. and Amici, Stefania and Ansalone, Luigi and Sabatini, Roberto},
	date = {2022-10},
	keywords = {{PRISMA}, Task analysis, Satellites, Space missions, Artificial intelligence, Convolutional neural networks, Fires, hyperspetral imagery, on-the-edge computing, Real-time systems, Wildfire detection},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\DBAF936B\\9967553.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\V2TSGZKH\\Spiller et al. - 2022 - Wildfire segmentation analysis from edge computing.pdf:application/pdf},
}

@article{drusch_sentinel-2_2012,
	title = {Sentinel-2: {ESA}'s Optical High-Resolution Mission for {GMES} Operational Services},
	volume = {120},
	issn = {0034-4257},
	url = {https://www.sciencedirect.com/science/article/pii/S0034425712000636},
	doi = {10.1016/j.rse.2011.11.026},
	series = {The Sentinel Missions - New Opportunities for Science},
	shorttitle = {Sentinel-2},
	abstract = {Global Monitoring for Environment and Security ({GMES}) is a joint initiative of the European Commission ({EC}) and the European Space Agency ({ESA}), designed to establish a European capacity for the provision and use of operational monitoring information for environment and security applications. {ESA}'s role in {GMES} is to provide the definition and the development of the space- and ground-related system elements. {GMES} Sentinel-2 mission provides continuity to services relying on multi-spectral high-resolution optical observations over global terrestrial surfaces. The key mission objectives for Sentinel-2 are: (1) To provide systematic global acquisitions of high-resolution multi-spectral imagery with a high revisit frequency, (2) to provide enhanced continuity of multi-spectral imagery provided by the {SPOT} (Satellite Pour l'Observation de la Terre) series of satellites, and (3) to provide observations for the next generation of operational products such as land-cover maps, land change detection maps, and geophysical variables. Consequently, Sentinel-2 will directly contribute to the Land Monitoring, Emergency Response, and Security services. The corresponding user requirements have driven the design toward a dependable multi-spectral Earth-observation system featuring the Multi Spectral Instrument ({MSI}) with 13 spectral bands spanning from the visible and the near infrared to the short wave infrared. The spatial resolution varies from 10m to 60m depending on the spectral band with a 290km field of view. This unique combination of high spatial resolution, wide field of view and spectral coverage will represent a major step forward compared to current multi-spectral missions. The mission foresees a series of satellites, each having a 7.25-year lifetime over a 15-year period starting with the launch of Sentinel-2A foreseen in 2013. During full operations two identical satellites will be maintained in the same orbit with a phase delay of 180° providing a revisit time of five days at the equator. This paper provides an overview of the {GMES} Sentinel-2 mission including a technical system concept overview, image quality, Level 1 data processing and operational applications.},
	pages = {25--36},
	journaltitle = {Remote Sensing of Environment},
	shortjournal = {Remote Sensing of Environment},
	author = {Drusch, M. and Del Bello, U. and Carlier, S. and Colin, O. and Fernandez, V. and Gascon, F. and Hoersch, B. and Isola, C. and Laberinti, P. and Martimort, P. and Meygret, A. and Spoto, F. and Sy, O. and Marchese, F. and Bargellini, P.},
	urldate = {2023-05-14},
	date = {2012-05-15},
	langid = {english},
	keywords = {Remote sensing, {GMES}, Land cover classification, Optical multi-spectral instrument, Sentinel-2},
	file = {ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\B8RZ846G\\S0034425712000636.html:text/html},
}

@inproceedings{spiller_transfer_2022,
	title = {Transfer Learning Analysis For Wildfire Segmentation Using Prisma Hyperspectral Imagery And Convolutional Neural Networks},
	doi = {10.1109/WHISPERS56178.2022.9955054},
	abstract = {In this work we present a segmentation study of wildfire scenarios using {PRISMA} hyperspectral data and a methodology based on convolutional neural networks and transfer learning. {PRISMA} (Precursore {IperSpettrale} della Missione Applicativa, Hyperspectral Precursor of the Application Mission) is the hyperspectral mission by {ASI} (Agenzia Spaziale Italiana, Italian Space Agency) launched in 2019 providing images with a spectral range of 0.4-2.5 {\textbackslash}mu {\textbackslash}textm and an average spectral resolution less than 10 nm. We used the {PRISMA} hypercube acquired during the Australian bushfires of December 2019 in New South Wales to train a one-dimensional convolutional neural network and perform a transfer learning in the Bootleg Fire of July 2021 in the Fremont-Winema National Forest in Oregon. The generalization ability of the network is discussed and potential future applications are presented.},
	eventtitle = {2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing ({WHISPERS})},
	pages = {1--5},
	booktitle = {2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing ({WHISPERS})},
	author = {Spiller, Dario and Amici, Stefania and Ansalone, Luigi},
	date = {2022-09},
	note = {{ISSN}: 2158-6276},
	keywords = {{PRISMA}, Image segmentation, Space missions, Fires, Convolutional Neural Networks, Hyperspectral Imagery, Image resolution, Signal processing, Training, Transfer learning, Transfer Learning, Wildfires},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\WSPUZ7B9\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\EW5Q8NQU\\Spiller et al. - 2022 - Transfer Learning Analysis For Wildfire Segmentati.pdf:application/pdf},
}

@article{hannuksela_high_2015,
	title = {The High Efficiency Image File Format Standard [Standards in a Nutshell]},
	volume = {32},
	issn = {1558-0792},
	doi = {10.1109/MSP.2015.2419292},
	abstract = {The High Efficiency Image File Format ({HEIF}) is a standard developed by the Moving Picture Experts Group ({MPEG}) for the storage of images and image sequences. The standard facilitates file encapsulation of data coded according to the High Efficiency Video Coding ({HEVC}) standard. The compression performance of {HEVC} is superior to any alternative image or image sequence coding format. {HEIF} includes a rich set of features building on top of the widely used {ISO} Base Media File Format ({ISOBMFF}), making {HEIF} superior feature-wise compared to other image file formats. This article provides an overview of the performance, features, and design of {HEIF}.},
	pages = {150--156},
	number = {4},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Hannuksela, Miska M. and Lainema, Jani and Malamal Vadakital, Vinod K.},
	date = {2015-07},
	note = {Conference Name: {IEEE} Signal Processing Magazine},
	keywords = {Image coding, Encoding, File systems, Image sequences, Media, Streaming media},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\485PJ3QW\\7123047.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\T3P4KZ94\\Hannuksela et al. - 2015 - The High Efficiency Image File Format Standard [St.pdf:application/pdf},
}

@article{delp_image_1979,
	title = {Image Compression Using Block Truncation Coding},
	volume = {27},
	issn = {1558-0857},
	doi = {10.1109/TCOM.1979.1094560},
	abstract = {A new technique for image compression called Block Truncation Coding ({BTC}) is presented and compared with transform and other techniques. The {BTC} algorithm uses a two-level (one-bit) nonparametric quantizer that adapts to local properties of the image. The quantizer that shows great promise is one which preserves the local sample moments. This quantizer produces good quality images that appear to be enhanced at data rates of 1.5 bits/picture element. No large data storage is required, and the computation is small. The quantizer is compared with standard (minimum mean-square error and mean absolute error) one-bit quantizers. Modifications of the basic {BTC} algorithm are discussed along with the performance of {BTC} in the presence of channel errors.},
	pages = {1335--1342},
	number = {9},
	journaltitle = {{IEEE} Transactions on Communications},
	author = {Delp, E. and Mitchell, O.},
	date = {1979-09},
	note = {Conference Name: {IEEE} Transactions on Communications},
	keywords = {Image coding, Algorithm design and analysis, Computer networks, Dynamic range, Equations, Image processing, Image storage, Memory, Queueing analysis, Routing},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\PY2CSVAV\\1094560.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\YXDYV52S\\Delp und Mitchell - 1979 - Image Compression Using Block Truncation Coding.pdf:application/pdf},
}

@misc{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	doi = {10.48550/arXiv.1609.04747},
	abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
	number = {{arXiv}:1609.04747},
	publisher = {{arXiv}},
	author = {Ruder, Sebastian},
	urldate = {2023-05-14},
	date = {2017-06-15},
	eprinttype = {arxiv},
	eprint = {1609.04747 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\97B98M55\\Ruder - 2017 - An overview of gradient descent optimization algor.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\47XU3HG4\\1609.html:text/html},
}

@article{karami_compression_2012,
	title = {Compression of Hyperspectral Images Using Discerete Wavelet Transform and Tucker Decomposition},
	volume = {5},
	issn = {2151-1535},
	doi = {10.1109/JSTARS.2012.2189200},
	abstract = {The compression of hyperspectral images ({HSIs}) has recently become a very attractive issue for remote sensing applications because of their volumetric data. In this paper, an efficient method for hyperspectral image compression is presented. The proposed algorithm, based on Discrete Wavelet Transform and Tucker Decomposition ({DWT}-{TD}), exploits both the spectral and the spatial information in the images. The core idea behind our proposed technique is to apply {TD} on the {DWT} coefficients of spectral bands of {HSIs}. We use {DWT} to effectively separate {HSIs} into different sub-images and {TD} to efficiently compact the energy of sub-images. We evaluate the effect of the proposed method on real {HSIs} and also compare the results with the well-known compression methods. The obtained results show a better performance of the proposed method. Moreover, we show the impact of compression {HSIs} on the supervised classification and linear unmixing.},
	pages = {444--450},
	number = {2},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	author = {Karami, Azam and Yazdi, Mehran and Mercier, Grégoire},
	date = {2012-04},
	note = {Conference Name: {IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	keywords = {Hyperspectral imaging, Compression, Image coding, Encoding, Correlation, Discrete wavelet transforms, hyperspectral images, noise reduction, Tensile stress, tucker decomposition, wavelet transform},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\EES2HP2F\\stamp.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\E624R2YJ\\Karami et al. - 2012 - Compression of Hyperspectral Images Using Disceret.pdf:application/pdf},
}

@article{saghri_adaptive_2010,
	title = {Adaptive two-stage Karhunen-Loeve-transform scheme for spectral decorrelation in hyperspectral bandwidth compression},
	volume = {49},
	issn = {0091-3286},
	url = {http://opticalengineering.spiedigitallibrary.org/article.aspx?doi=10.1117/1.3425656},
	doi = {10.1117/1.3425656},
	pages = {057001},
	number = {5},
	journaltitle = {Optical Engineering},
	shortjournal = {Opt. Eng},
	author = {Saghri, John A.},
	urldate = {2023-05-16},
	date = {2010-05-01},
	langid = {english},
	file = {Adaptive two-stage Karhunen-Loeve-transform scheme for spectral decorrelation in hyperspectral bandwidth compression, Optical Engineering | 10.1117/1.3425656 | DeepDyve:C\:\\Users\\Niklas\\Zotero\\storage\\DTNINFHJ\\adaptive-two-stage-karhunen-loeve-transform-scheme-for-spectral-0BV7Hta5Sp.html:text/html},
}

@inproceedings{kuester_transferability_2022,
	title = {Transferability of Convolutional Autoencoder Model For Lossy Compression to Unknown Hyperspectral Prisma Data},
	doi = {10.1109/WHISPERS56178.2022.9955109},
	abstract = {This work addresses the challenge of the portability of Autoencoder models for the lossy compression of different spatially independent and unknown hyperspectral satellite data. We propose an advanced 1D-Convolutional Autoencoder architecture for lossy hyperspectral data compression with high transferability to unknown spectral signatures. In the first experiment, the model is trained on a single {PRISMA} data set, and in the second experiment it is trained on five {PRISMA} data sets from all over the world. The abstraction ability of the two models is verified by processing six spatially independent hyperspectral {PRISMA} satellite data sets. The evaluation is based on the reconstruction accuracy using the {SNR} and {SA} metrics and compares it to other learning-based lossy compression techniques. We demonstrate the high transferability and generalization of our 1D-Convolutional Autoencoder for a fixed compression ratio on each {PRISMA} satellite data set, which results in superior reconstruction accuracy compared to state-of-the-art methods.},
	eventtitle = {2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing ({WHISPERS})},
	pages = {1--5},
	booktitle = {2022 12th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing ({WHISPERS})},
	author = {Kuester, Jannick and Gross, Wolfgang and Schreiner, Simon and Heizmann, Michael and Middelmann, Wolfgang},
	date = {2022-09},
	note = {{ISSN}: 2158-6276},
	keywords = {Data mining, Satellites, Autoencoder, Conferences, Convolution, Data compression, Data models, dimensionality reduction, feature extraction, hyperspectral data compression, hyperspectral imaging, Measurement, spectral analysis},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\8KKSXYLJ\\9955109.html:text/html},
}

@article{conoscenti_constant_2016,
	title = {Constant {SNR}, Rate Control, and Entropy Coding for Predictive Lossy Hyperspectral Image Compression},
	volume = {54},
	issn = {1558-0644},
	doi = {10.1109/TGRS.2016.2603998},
	abstract = {Predictive lossy compression has been shown to represent a very flexible framework for lossless and lossy onboard compression of multispectral and hyperspectral images with quality and rate control. In this paper, we improve predictive lossy compression in several ways, using a standard issued by the Consultative Committee on Space Data Systems, namely {CCSDS}-123, as an example of application. First, exploiting the flexibility in the error control process, we propose a constant-signal-to-noise-ratio algorithm that bounds the maximum relative error between each pixel of the reconstructed image and the corresponding pixel of the original image. This is very useful to avoid low-energy areas of the image being affected by large errors. Second, we propose a new rate control algorithm that has very low complexity and provides performance equal to or better than existing work. Third, we investigate several entropy coding schemes that can speed up the hardware implementation of the algorithm and, at the same time, improve coding efficiency. These advances make predictive lossy compression an extremely appealing framework for onboard systems due to its simplicity, flexibility, and coding efficiency.},
	pages = {7431--7441},
	number = {12},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	author = {Conoscenti, Marco and Coppola, Riccardo and Magli, Enrico},
	date = {2016-12},
	note = {Conference Name: {IEEE} Transactions on Geoscience and Remote Sensing},
	keywords = {Hyperspectral imaging, Image coding, Entropy coding, Hyperspectral image coding, lossy compression predictive coding, multispectral image compression, Prediction algorithms, Quantization (signal), rate control, Signal to noise ratio},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\REXHJ9X5\\7570236.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\3J4XU2DP\\Conoscenti et al. - 2016 - Constant SNR, Rate Control, and Entropy Coding for.pdf:application/pdf},
}

@article{hernandez-cabronero_ccsds_2021,
	title = {The {CCSDS} 123.0-B-2 “Low-Complexity Lossless and Near-Lossless Multispectral and Hyperspectral Image Compression” Standard: A comprehensive review},
	volume = {9},
	issn = {2168-6831},
	doi = {10.1109/MGRS.2020.3048443},
	shorttitle = {The {CCSDS} 123.0-B-2 “Low-Complexity Lossless and Near-Lossless Multispectral and Hyperspectral Image Compression” Standard},
	abstract = {The Consultative Committee for Space Data Systems ({CCSDS}) published the {CCSDS} 123.0-B-2, “Low-Complexity Lossless and Near-Lossless Multispectral and Hyperspectral Image Compression” standard. This standard extends the previous issue, {CCSDS} 123.0-B-1, which supported only lossless compression, while maintaining backward compatibility. The main novelty of the new issue is support for near-lossless compression, i.e., lossy compression with user-defined absolute and/or relative error limits in the reconstructed images. This new feature is achieved via closed-loop quantization of prediction errors. Two further additions arise from the new near-lossless support: first, the calculation of predicted sample values using sample representatives that may not be equal to the reconstructed sample values, and, second, a new hybrid entropy coder designed to provide enhanced compression performance for low-entropy data, prevalent when nonlossless compression is used. These new features enable significantly smaller compressed data volumes than those achievable with {CCSDS} 123.0-B-1 while controlling the quality of the decompressed images. As a result, larger amounts of valuable information can be retrieved given a set of bandwidth and energy consumption constraints.},
	pages = {102--119},
	number = {4},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Magazine},
	author = {Hernández-Cabronero, Miguel and Kiely, Aaron B. and Klimesh, Matthew and Blanes, Ian and Ligo, Jonathan and Magli, Enrico and Serra-Sagristà, Joan},
	date = {2021-12},
	note = {Conference Name: {IEEE} Geoscience and Remote Sensing Magazine},
	keywords = {Image coding, Quantization (signal), Compressors, Field programmable gate arrays, Hardware, Throughput, Tutorials},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Niklas\\Zotero\\storage\\4KY3Y6VI\\9352211.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\5RNET79W\\Hernández-Cabronero et al. - 2021 - The CCSDS 123.0-B-2 “Low-Complexity Lossless and N.pdf:application/pdf},
}

@misc{vaswani_attention_2017,
	title = {Attention Is All You Need},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	number = {{arXiv}:1706.03762},
	publisher = {{arXiv}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2023-05-20},
	date = {2017-12-05},
	eprinttype = {arxiv},
	eprint = {1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\XVM7UZE4\\Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\LIDS9AJS\\1706.html:text/html},
}

@misc{liu_non-local_2019,
	title = {Non-local Attention Optimized Deep Image Compression},
	url = {http://arxiv.org/abs/1904.09757},
	doi = {10.48550/arXiv.1904.09757},
	abstract = {This paper proposes a novel Non-Local Attention Optimized Deep Image Compression ({NLAIC}) framework, which is built on top of the popular variational auto-encoder ({VAE}) structure. Our {NLAIC} framework embeds non-local operations in the encoders and decoders for both image and latent feature probability information (known as hyperprior) to capture both local and global correlations, and apply attention mechanism to generate masks that are used to weigh the features for the image and hyperprior, which implicitly adapt bit allocation for different features based on their importance. Furthermore, both hyperpriors and spatial-channel neighbors of the latent features are used to improve entropy coding. The proposed model outperforms the existing methods on Kodak dataset, including learned (e.g., Balle2019, Balle2018) and conventional (e.g., {BPG}, {JPEG}2000, {JPEG}) image compression methods, for both {PSNR} and {MS}-{SSIM} distortion metrics.},
	number = {{arXiv}:1904.09757},
	publisher = {{arXiv}},
	author = {Liu, Haojie and Chen, Tong and Guo, Peiyao and Shen, Qiu and Cao, Xun and Wang, Yao and Ma, Zhan},
	urldate = {2023-05-20},
	date = {2019-04-22},
	eprinttype = {arxiv},
	eprint = {1904.09757 [cs, eess]},
	note = {version: 1},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\W5CBDJEQ\\Liu et al. - 2019 - Non-local Attention Optimized Deep Image Compressi.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\CH8PZNK3\\1904.html:text/html},
}

@misc{li_learning_2017,
	title = {Learning Convolutional Networks for Content-weighted Image Compression},
	url = {http://arxiv.org/abs/1703.10553},
	doi = {10.48550/arXiv.1703.10553},
	abstract = {Lossy image compression is generally formulated as a joint rate-distortion optimization to learn encoder, quantizer, and decoder. However, the quantizer is non-differentiable, and discrete entropy estimation usually is required for rate control. These make it very challenging to develop a convolutional network ({CNN})-based image compression system. In this paper, motivated by that the local information content is spatially variant in an image, we suggest that the bit rate of the different parts of the image should be adapted to local content. And the content aware bit rate is allocated under the guidance of a content-weighted importance map. Thus, the sum of the importance map can serve as a continuous alternative of discrete entropy estimation to control compression rate. And binarizer is adopted to quantize the output of encoder due to the binarization scheme is also directly defined by the importance map. Furthermore, a proxy function is introduced for binary operation in backward propagation to make it differentiable. Therefore, the encoder, decoder, binarizer and importance map can be jointly optimized in an end-to-end manner by using a subset of the {ImageNet} database. In low bit rate image compression, experiments show that our system significantly outperforms {JPEG} and {JPEG} 2000 by structural similarity ({SSIM}) index, and can produce the much better visual result with sharp edges, rich textures, and fewer artifacts.},
	number = {{arXiv}:1703.10553},
	publisher = {{arXiv}},
	author = {Li, Mu and Zuo, Wangmeng and Gu, Shuhang and Zhao, Debin and Zhang, David},
	urldate = {2023-05-21},
	date = {2017-09-19},
	eprinttype = {arxiv},
	eprint = {1703.10553 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\E868VFF3\\Li et al. - 2017 - Learning Convolutional Networks for Content-weight.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\UNNVDSV4\\1703.html:text/html},
}

@misc{mentzer_conditional_2019,
	title = {Conditional Probability Models for Deep Image Compression},
	url = {http://arxiv.org/abs/1801.04260},
	doi = {10.48550/arXiv.1801.04260},
	abstract = {Deep Neural Networks trained as image auto-encoders have recently emerged as a promising direction for advancing the state-of-the-art in image compression. The key challenge in learning such networks is twofold: To deal with quantization, and to control the trade-off between reconstruction error (distortion) and entropy (rate) of the latent image representation. In this paper, we focus on the latter challenge and propose a new technique to navigate the rate-distortion trade-off for an image compression auto-encoder. The main idea is to directly model the entropy of the latent representation by using a context model: A 3D-{CNN} which learns a conditional probability model of the latent distribution of the auto-encoder. During training, the auto-encoder makes use of the context model to estimate the entropy of its representation, and the context model is concurrently updated to learn the dependencies between the symbols in the latent representation. Our experiments show that this approach, when measured in {MS}-{SSIM}, yields a state-of-the-art image compression system based on a simple convolutional auto-encoder.},
	number = {{arXiv}:1801.04260},
	publisher = {{arXiv}},
	author = {Mentzer, Fabian and Agustsson, Eirikur and Tschannen, Michael and Timofte, Radu and Van Gool, Luc},
	urldate = {2023-05-21},
	date = {2019-06-04},
	eprinttype = {arxiv},
	eprint = {1801.04260 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\TH2KSN5T\\Mentzer et al. - 2019 - Conditional Probability Models for Deep Image Comp.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\49JG99X2\\1801.html:text/html},
}

@article{witten_arithmetic_1987,
	title = {Arithmetic coding for data compression},
	volume = {30},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/214762.214771},
	doi = {10.1145/214762.214771},
	abstract = {The state of the art in data compression is arithmetic coding, not the better-known Huffman method. Arithmetic coding gives greater compression, is faster for adaptive models, and clearly separates the model from the channel encoding.},
	pages = {520--540},
	number = {6},
	journaltitle = {Communications of the {ACM}},
	shortjournal = {Commun. {ACM}},
	author = {Witten, Ian H. and Neal, Radford M. and Cleary, John G.},
	urldate = {2023-05-29},
	date = {1987-06},
	langid = {english},
}

@misc{said_introduction_2023,
	title = {Introduction to Arithmetic Coding -- Theory and Practice},
	url = {http://arxiv.org/abs/2302.00819},
	doi = {10.48550/arXiv.2302.00819},
	abstract = {This introduction to arithmetic coding is divided in two parts. The first explains how and why arithmetic coding works. We start presenting it in very general terms, so that its simplicity is not lost under layers of implementation details. Next, we show some of its basic properties, which are later used in the computational techniques required for a practical implementation. In the second part, we cover the practical implementation aspects, including arithmetic operations with low precision, the subdivision of coding and modeling, and the realization of adaptive encoders. We also analyze the arithmetic coding computational complexity, and techniques to reduce it.},
	number = {{arXiv}:2302.00819},
	publisher = {{arXiv}},
	author = {Said, Amir},
	urldate = {2023-05-29},
	date = {2023-02-01},
	eprinttype = {arxiv},
	eprint = {2302.00819 [cs, math]},
	keywords = {Computer Science - Information Theory, Computer Science - Multimedia},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\UHYAYW76\\Said - 2023 - Introduction to Arithmetic Coding -- Theory and Pr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\8NK4XXKY\\2302.html:text/html},
}

@misc{fuchs_hyspecnet-11k_2023,
	title = {{HySpecNet}-11k: A Large-Scale Hyperspectral Dataset for Benchmarking Learning-Based Hyperspectral Image Compression Methods},
	url = {http://arxiv.org/abs/2306.00385},
	doi = {10.48550/arXiv.2306.00385},
	shorttitle = {{HySpecNet}-11k},
	abstract = {The development of learning-based hyperspectral image compression methods has recently attracted great attention in remote sensing. Such methods require a high number of hyperspectral images to be used during training to optimize all parameters and reach a high compression performance. However, existing hyperspectral datasets are not sufficient to train and evaluate learning-based compression methods, which hinders the research in this field. To address this problem, in this paper we present {HySpecNet}-11k that is a large-scale hyperspectral benchmark dataset made up of 11,483 nonoverlapping image patches. Each patch is a portion of 128 \${\textbackslash}times\$ 128 pixels with 224 spectral bands and a ground sample distance of 30 m. We exploit {HySpecNet}-11k to benchmark the current state of the art in learning-based hyperspectral image compression by focussing our attention on various 1D, 2D and 3D convolutional autoencoder architectures. Nevertheless, {HySpecNet}-11k can be used for any unsupervised learning task in the framework of hyperspectral image analysis. The dataset, our code and the pre-trained weights are publicly available at https://hyspecnet.rsim.berlin .},
	number = {{arXiv}:2306.00385},
	publisher = {{arXiv}},
	author = {Fuchs, Martin Hermann Paul and Demir, Begüm},
	urldate = {2023-06-05},
	date = {2023-06-02},
	eprinttype = {arxiv},
	eprint = {2306.00385 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\P4GKGHRY\\Fuchs und Demir - 2023 - HySpecNet-11k A Large-Scale Hyperspectral Dataset.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\PXQ8ISGF\\2306.html:text/html},
}
