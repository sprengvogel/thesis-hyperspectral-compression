
@article{de_carvalho_junior_spectral_2000,
	title = {Spectral Correlation Mapper ({SCM}): An Improvement on the Spectral Angle Mapper ({SAM})},
	shorttitle = {Spectral Correlation Mapper ({SCM})},
	author = {de Carvalho Júnior, Osmar and Meneses, Paulo},
	date = {2000-01-01},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\TVIB6KNC\\de Carvalho Júnior and Meneses - 2000 - Spectral Correlation Mapper (SCM) An Improvement .pdf:application/pdf},
}

@incollection{fowler_three-dimensional_2007,
	title = {Three-Dimensional Wavelet-Based Compression of Hyperspectral Imagery},
	isbn = {978-0-470-12462-8},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470124628.ch14},
	abstract = {This chapter contains sections titled: Introduction Embedded Wavelet-Based Compression of 3D Imagery Performance Measures for Hyperspectral Compression Prominent Techniques for Significance-Map Coding {JPEG}2000 Encoding Strategies Compression Performance Summary References},
	pages = {379--407},
	booktitle = {Hyperspectral Data Exploitation},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Fowler, James E. and Rucker, Justin T.},
	urldate = {2022-10-01},
	date = {2007},
	langid = {english},
	doi = {10.1002/9780470124628.ch14},
	note = {Section: 14
\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470124628.ch14},
	keywords = {hyperspectral compression performance measures, significance-map coding in hyperspectral imagery, three-dimensional hyperspectral imagery wavelet-based compression},
	file = {Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\E7N66AJA\\9780470124628.html:text/html},
}

@article{du_low-complexity_2008,
	title = {Low-Complexity Principal Component Analysis for Hyperspectral Image Compression},
	volume = {22},
	issn = {1094-3420, 1741-2846},
	url = {http://journals.sagepub.com/doi/10.1177/1094342007088380},
	doi = {10.1177/1094342007088380},
	abstract = {Principal component analysis ({PCA}) is an effective tool for spectral decorrelation of hyperspectral imagery, and {PCAbased} spectral transforms have been employed successfully in conjunction with {JPEG}2000 for hyperspectral image compression. However, the computational cost of determining the data-dependent {PCA} transform is high because of its traditional eigendecomposition implementation which requires calculation of a covariance matrix across the data. Several strategies for reducing the computation burden of {PCA} are explored, including both spatial and spectral subsampling in the covariance calculation as well as an iterative algorithm that circumvents determination of the covariance matrix entirely. Experimental results investigate the impacts of such low-complexity {PCA} on {JPEG}2000 compression of hyperspectral images, focusing on rate-distortion performance as well as data-analysis performance at an anomaly-detection task.},
	pages = {438--448},
	number = {4},
	journaltitle = {The International Journal of High Performance Computing Applications},
	shortjournal = {The International Journal of High Performance Computing Applications},
	author = {Du, Qian and Fowler, James E.},
	urldate = {2022-10-01},
	date = {2008-11},
	langid = {english},
	file = {Du and Fowler - 2008 - Low-Complexity Principal Component Analysis for Hy.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\667RIT6K\\Du and Fowler - 2008 - Low-Complexity Principal Component Analysis for Hy.pdf:application/pdf},
}

@online{kuester_transferability_2022,
	title = {Transferability of Convolutional Autoencoder Model for Lossy Compression to Unknown Hyperspectral {PRISMA} Data},
	url = {https://tubcloud.tu-berlin.de/s/dnAzTNsC5762HHp},
	abstract = {{TU} Berlin - Wir haben die Ideen für die Zukunft. Zum Nutzen der Gesellschaft.},
	titleaddon = {{TU} Berlin},
	author = {Kuester, Jannick and Gross, Wolfgang and Schreiner, Simon and Heizmann, Michael and Middelmann, Wolfgang},
	urldate = {2022-10-01},
	date = {2022},
	langid = {english},
	keywords = {Hyperspectral},
}

@misc{balle_variational_2018,
	title = {Variational image compression with a scale hyperprior},
	url = {http://arxiv.org/abs/1802.01436},
	doi = {10.48550/arXiv.1802.01436},
	abstract = {We describe an end-to-end trainable model for image compression based on variational autoencoders. The model incorporates a hyperprior to effectively capture spatial dependencies in the latent representation. This hyperprior relates to side information, a concept universal to virtually all modern image codecs, but largely unexplored in image compression using artificial neural networks ({ANNs}). Unlike existing autoencoder compression methods, our model trains a complex prior jointly with the underlying autoencoder. We demonstrate that this model leads to state-of-the-art image compression when measuring visual quality using the popular {MS}-{SSIM} index, and yields rate-distortion performance surpassing published {ANN}-based methods when evaluated using a more traditional metric based on squared error ({PSNR}). Furthermore, we provide a qualitative comparison of models trained for different distortion metrics.},
	number = {{arXiv}:1802.01436},
	publisher = {{arXiv}},
	author = {Ballé, Johannes and Minnen, David and Singh, Saurabh and Hwang, Sung Jin and Johnston, Nick},
	urldate = {2022-10-01},
	date = {2018-05-01},
	eprinttype = {arxiv},
	eprint = {1802.01436 [cs, eess, math]},
	note = {Number: {arXiv}:1802.01436},
	keywords = {Computer Science - Information Theory, Electrical Engineering and Systems Science - Image and Video Processing, {RGB}},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\C3LJ7W7J\\Ballé et al. - 2018 - Variational image compression with a scale hyperpr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\9U5KFP5D\\1802.html:text/html},
}

@misc{lu_transformer-based_2021,
	title = {Transformer-based Image Compression},
	url = {http://arxiv.org/abs/2111.06707},
	doi = {10.48550/arXiv.2111.06707},
	abstract = {A Transformer-based Image Compression ({TIC}) approach is developed which reuses the canonical variational autoencoder ({VAE}) architecture with paired main and hyper encoder-decoders. Both main and hyper encoders are comprised of a sequence of neural transformation units ({NTUs}) to analyse and aggregate important information for more compact representation of input image, while the decoders mirror the encoder-side operations to generate pixel-domain image reconstruction from the compressed bitstream. Each {NTU} is consist of a Swin Transformer Block ({STB}) and a convolutional layer (Conv) to best embed both long-range and short-range information; In the meantime, a casual attention module ({CAM}) is devised for adaptive context modeling of latent features to utilize both hyper and autoregressive priors. The {TIC} rivals with state-of-the-art approaches including deep convolutional neural networks ({CNNs}) based learnt image coding ({LIC}) methods and handcrafted rules-based intra profile of recently-approved Versatile Video Coding ({VVC}) standard, and requires much less model parameters, e.g., up to 45\% reduction to leading-performance {LIC}.},
	number = {{arXiv}:2111.06707},
	publisher = {{arXiv}},
	author = {Lu, Ming and Guo, Peiyao and Shi, Huiqing and Cao, Chuntong and Ma, Zhan},
	urldate = {2022-10-01},
	date = {2021-11-12},
	eprinttype = {arxiv},
	eprint = {2111.06707 [cs, eess]},
	note = {Number: {arXiv}:2111.06707},
	keywords = {Electrical Engineering and Systems Science - Image and Video Processing, {RGB}, Computer Science - Computer Vision and Pattern Recognition, Transformer},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CKTYQ84K\\Lu et al. - 2021 - Transformer-based Image Compression.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\WR8EMMFQ\\2111.html:text/html},
}

@inproceedings{zou_devil_2022,
	title = {The Devil Is in the Details: Window-Based Attention for Image Compression},
	url = {https://openaccess.thecvf.com/content/CVPR2022/html/Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.html},
	shorttitle = {The Devil Is in the Details},
	eventtitle = {Proceedings of the {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition},
	pages = {17492--17501},
	author = {Zou, Renjie and Song, Chunfeng and Zhang, Zhaoxiang},
	urldate = {2022-10-01},
	date = {2022},
	langid = {english},
	keywords = {{RGB}},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CHNFZ8FA\\Zou et al. - 2022 - The Devil Is in the Details Window-Based Attentio.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\HQJ9Z8GI\\Zou_The_Devil_Is_in_the_Details_Window-Based_Attention_for_Image_CVPR_2022_paper.html:text/html},
}

@article{hong_spectralformer_2022,
	title = {{SpectralFormer}: Rethinking Hyperspectral Image Classification with Transformers},
	volume = {60},
	issn = {0196-2892, 1558-0644},
	url = {http://arxiv.org/abs/2107.02988},
	doi = {10.1109/TGRS.2021.3130716},
	shorttitle = {{SpectralFormer}},
	abstract = {Hyperspectral ({HS}) images are characterized by approximately contiguous spectral information, enabling the fine identification of materials by capturing subtle spectral discrepancies. Owing to their excellent locally contextual modeling ability, convolutional neural networks ({CNNs}) have been proven to be a powerful feature extractor in {HS} image classification. However, {CNNs} fail to mine and represent the sequence attributes of spectral signatures well due to the limitations of their inherent network backbone. To solve this issue, we rethink {HS} image classification from a sequential perspective with transformers, and propose a novel backbone network called {\textbackslash}ul\{{SpectralFormer}\}. Beyond band-wise representations in classic transformers, {SpectralFormer} is capable of learning spectrally local sequence information from neighboring bands of {HS} images, yielding group-wise spectral embeddings. More significantly, to reduce the possibility of losing valuable information in the layer-wise propagation process, we devise a cross-layer skip connection to convey memory-like components from shallow to deep layers by adaptively learning to fuse "soft" residuals across layers. It is worth noting that the proposed {SpectralFormer} is a highly flexible backbone network, which can be applicable to both pixel- and patch-wise inputs. We evaluate the classification performance of the proposed {SpectralFormer} on three {HS} datasets by conducting extensive experiments, showing the superiority over classic transformers and achieving a significant improvement in comparison with state-of-the-art backbone networks. The codes of this work will be available at https://github.com/danfenghong/{IEEE}\_TGRS\_SpectralFormer for the sake of reproducibility.},
	pages = {1--15},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	shortjournal = {{IEEE} Trans. Geosci. Remote Sensing},
	author = {Hong, Danfeng and Han, Zhu and Yao, Jing and Gao, Lianru and Zhang, Bing and Plaza, Antonio and Chanussot, Jocelyn},
	urldate = {2022-10-01},
	date = {2022},
	eprinttype = {arxiv},
	eprint = {2107.02988 [cs]},
	keywords = {Hyperspectral, Computer Science - Computer Vision and Pattern Recognition, Transformer, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\22H8XK7D\\Hong et al. - 2022 - SpectralFormer Rethinking Hyperspectral Image Cla.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\NFISRMRG\\2107.html:text/html},
}

@article{he_spatial-spectral_2021,
	title = {Spatial-Spectral Transformer for Hyperspectral Image Classification},
	volume = {13},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/3/498},
	doi = {10.3390/rs13030498},
	abstract = {Recently, a great many deep convolutional neural network ({CNN})-based methods have been proposed for hyperspectral image ({HSI}) classification. Although the proposed {CNN}-based methods have the advantages of spatial feature extraction, they are difficult to handle the sequential data with and {CNNs} are not good at modeling the long-range dependencies. However, the spectra of {HSI} are a kind of sequential data, and {HSI} usually contains hundreds of bands. Therefore, it is difficult for {CNNs} to handle {HSI} processing well. On the other hand, the Transformer model, which is based on an attention mechanism, has proved its advantages in processing sequential data. To address the issue of capturing relationships of sequential spectra in {HSI} in a long distance, in this study, Transformer is investigated for {HSI} classification. Specifically, in this study, a new classification framework titled spatial-spectral Transformer ({SST}) is proposed for {HSI} classification. In the proposed {SST}, a well-designed {CNN} is used to extract the spatial features, and a modified Transformer (a Transformer with dense connection, i.e., {DenseTransformer}) is proposed to capture sequential spectra relationships, and multilayer perceptron is used to finish the final classification task. Furthermore, dynamic feature augmentation, which aims to alleviate the overfitting problem and therefore generalize the model well, is proposed and added to the {SST} ({SST}-{FA}). In addition, to address the issue of limited training samples in {HSI} classification, transfer learning is combined with {SST}, and another classification framework titled transferring-{SST} (T-{SST}) is proposed. At last, to mitigate the overfitting problem and improve the classification accuracy, label smoothing is introduced for the T-{SST}-based classification framework (T-{SST}-L). The proposed {SST}, {SST}-{FA}, T-{SST}, and T-{SST}-L are tested on three widely used hyperspectral datasets. The obtained results reveal that the proposed models provide competitive results compared to the state-of-the-art methods, which shows that the concept of Transformer opens a new window for {HSI} classification.},
	pages = {498},
	number = {3},
	journaltitle = {Remote Sensing},
	author = {He, Xin and Chen, Yushi and Lin, Zhouhan},
	urldate = {2022-10-01},
	date = {2021-01},
	langid = {english},
	note = {Number: 3
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Hyperspectral, Transformer, classification, convolutional neural network ({CNN}), hyperspectral image ({HSI})},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\MAXP6GXN\\He et al. - 2021 - Spatial-Spectral Transformer for Hyperspectral Ima.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\NASN78XL\\498.html:text/html},
}

@article{guo_learned_2021,
	title = {Learned Hyperspectral Compression Using a Student’s T Hyperprior},
	volume = {13},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/21/4390},
	doi = {10.3390/rs13214390},
	abstract = {Hyperspectral compression is one of the most common techniques in hyperspectral image processing. Most recent learned image compression methods have exhibited excellent rate-distortion performance for natural images, but they have not been fully explored for hyperspectral compression tasks. In this paper, we propose a trainable network architecture for hyperspectral compression tasks, which not only considers the anisotropic characteristic of hyperspectral images but also embeds an accurate entropy model using the non-Gaussian prior knowledge of hyperspectral images and nonlinear transform. Specifically, we first design a spatial-spectral block, involving a spatial net and a spectral net as the base components of the core autoencoder, which is more consistent with the anisotropic hyperspectral cubes than the existing compression methods based on deep learning. Then, we design a Student’s T hyperprior that merges the statistics of the latents and the side information concepts into a unified neural network to provide an accurate entropy model used for entropy coding. This not only remarkably enhances the flexibility of the entropy model by adjusting various values of the degree of freedom, but also leads to a superior rate-distortion performance. The results illustrate that the proposed compression scheme supersedes the Gaussian hyperprior universally for virtually all learned natural image codecs and the optimal linear transform coding methods for hyperspectral compression. Specifically, the proposed method provides a 1.51\% to 59.95\% average increase in peak signal-to-noise ratio, a 0.17\% to 18.17\% average increase in the structural similarity index metric and a 6.15\% to 64.60\% average reduction in spectral angle mapping over three public hyperspectral datasets compared to the Gaussian hyperprior and the optimal linear transform coding methods.},
	pages = {4390},
	number = {21},
	journaltitle = {Remote Sensing},
	author = {Guo, Yuanyuan and Chong, Yanwen and Ding, Yun and Pan, Shaoming and Gu, Xiaolin},
	urldate = {2022-10-01},
	date = {2021-01},
	langid = {english},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Hyperspectral, artificial neural networks, entropy model, hyperspectral compression, student’s T distribution},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\TF97UC2T\\Guo et al. - 2021 - Learned Hyperspectral Compression Using a Student’.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\DRVI6RM7\\4390.html:text/html},
}

@inproceedings{minnen_joint_2018,
	title = {Joint Autoregressive and Hierarchical Priors for Learned Image Compression},
	volume = {31},
	url = {https://proceedings.neurips.cc/paper/2018/hash/53edebc543333dfbf7c5933af792c9c4-Abstract.html},
	abstract = {Recent models for learned image compression are based on autoencoders that learn approximately invertible mappings from pixels to a quantized latent representation. The transforms are combined with an entropy model, which is a prior on the latent representation that can be used with standard arithmetic coding algorithms to generate a compressed bitstream. Recently, hierarchical entropy models were introduced as a way to exploit more structure in the latents than previous fully factorized priors, improving compression performance while maintaining end-to-end optimization. Inspired by the success of autoregressive priors in probabilistic generative models, we examine autoregressive, hierarchical, and combined priors as alternatives, weighing their costs and benefits in the context of image compression. While it is well known that autoregressive models can incur a significant computational penalty, we find that in terms of compression performance, autoregressive and hierarchical priors are complementary and can be combined to exploit the probabilistic structure in the latents better than all previous learned models. The combined model yields state-of-the-art rate-distortion performance and generates smaller files than existing methods: 15.8\% rate reductions over the baseline hierarchical model and 59.8\%, 35\%, and 8.4\% savings over {JPEG}, {JPEG}2000, and {BPG}, respectively. To the best of our knowledge, our model is the first learning-based method to outperform the top standard image codec ({BPG}) on both the {PSNR} and {MS}-{SSIM} distortion metrics.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Minnen, David and Ballé, Johannes and Toderici, George D},
	urldate = {2022-10-01},
	date = {2018},
	keywords = {{RGB}, Hierarchical Priors},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\3P92WYEA\\Minnen et al. - 2018 - Joint Autoregressive and Hierarchical Priors for L.pdf:application/pdf},
}

@article{la_grassa_hyperspectral_2022,
	title = {Hyperspectral Data Compression Using Fully Convolutional Autoencoder},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/14/10/2472},
	doi = {10.3390/rs14102472},
	abstract = {In space science and satellite imagery, better resolution of the data information obtained makes images clearer and interpretation more accurate. However, the huge data volume gained by the complex on-board satellite instruments becomes a problem that needs to be managed carefully. To reduce the data volume to be stored and transmitted on-ground, the signals received should be compressed, allowing a good original source representation in the reconstruction step. Image compression covers a key role in space science and satellite imagery and, recently, deep learning models have achieved remarkable results in computer vision. In this paper, we propose a spectral signals compressor network based on deep convolutional autoencoder ({SSCNet}) and we conduct experiments over multi/hyperspectral and {RGB} datasets reporting improvements over all baselines used as benchmarks and than the {JPEG} family algorithm. Experimental results demonstrate the effectiveness in the compression ratio and spectral signal reconstruction and the robustness with a data type greater than 8 bits, clearly exhibiting better results using the {PSNR}, {SSIM}, and {MS}-{SSIM} evaluation criteria.},
	pages = {2472},
	number = {10},
	journaltitle = {Remote Sensing},
	author = {La Grassa, Riccardo and Re, Cristina and Cremonese, Gabriele and Gallo, Ignazio},
	urldate = {2022-10-01},
	date = {2022-01},
	langid = {english},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Hyperspectral, convolutional neural network ({CNN}), autoencoder, data compression, remote sensing, satellite images},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\BFRQTF6U\\La Grassa et al. - 2022 - Hyperspectral Data Compression Using Fully Convolu.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\RFNXFEDG\\htm.html:text/html},
}

@misc{balle_end--end_2017,
	title = {End-to-end Optimized Image Compression},
	url = {http://arxiv.org/abs/1611.01704},
	doi = {10.48550/arXiv.1611.01704},
	abstract = {We describe an image compression method, consisting of a nonlinear analysis transformation, a uniform quantizer, and a nonlinear synthesis transformation. The transforms are constructed in three successive stages of convolutional linear filters and nonlinear activation functions. Unlike most convolutional neural networks, the joint nonlinearity is chosen to implement a form of local gain control, inspired by those used to model biological neurons. Using a variant of stochastic gradient descent, we jointly optimize the entire model for rate-distortion performance over a database of training images, introducing a continuous proxy for the discontinuous loss function arising from the quantizer. Under certain conditions, the relaxed loss function may be interpreted as the log likelihood of a generative model, as implemented by a variational autoencoder. Unlike these models, however, the compression model must operate at any given point along the rate-distortion curve, as specified by a trade-off parameter. Across an independent set of test images, we find that the optimized method generally exhibits better rate-distortion performance than the standard {JPEG} and {JPEG} 2000 compression methods. More importantly, we observe a dramatic improvement in visual quality for all images at all bit rates, which is supported by objective quality estimates using {MS}-{SSIM}.},
	number = {{arXiv}:1611.01704},
	publisher = {{arXiv}},
	author = {Ballé, Johannes and Laparra, Valero and Simoncelli, Eero P.},
	urldate = {2022-10-01},
	date = {2017-03-03},
	eprinttype = {arxiv},
	eprint = {1611.01704 [cs, math]},
	note = {Number: {arXiv}:1611.01704},
	keywords = {Computer Science - Information Theory, {RGB}, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Niklas\\Zotero\\storage\\6UR64VEC\\Ballé et al. - 2017 - End-to-end Optimized Image Compression.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\2LTVDF9V\\1611.html:text/html},
}

@inproceedings{kuester_1d-convolutional_2021,
	title = {1d-Convolutional Autoencoder Based Hyperspectral Data Compression},
	rights = {© 2021. This work is published under https://creativecommons.org/licenses/by/4.0/ (the “License”). Notwithstanding the {ProQuest} Terms and Conditions, you may use this content in accordance with the terms of the License.},
	url = {https://www.proquest.com/docview/2585318626},
	doi = {10.5194/isprs-archives-XLIII-B1-2021-15-2021},
	abstract = {Hyperspectral sensor technology has been advancing in recent years and become more practical to tackle a variety of applications. The arising issues of data transmission and storage can be addressed with the help of compression. To minimize the loss of important information, high spectral correlation between adjacent bands is exploited. In this paper, we introduce an approach to compress hyperspectral data based on a 1D-Convolutional Autoencoder. Compression is achieved through reducing correlation by transforming the spectral signature into a low-dimensional space, while simultaneously preserving the significant features. The focus lies on compression of the spectral dimension. The spatial dimension is not used in the compression in order not to falsify correlation between the spectral dimension and accuracy of the reconstruction. The proposed 1D-Convolutional Autoencoder efficiently finds and extracts features relevant for compression. Additionally, it can be exploited as a feature extractor or for dimensionality reduction. The hyperspectral data sets Greding Village and Pavia University were used for the training and the evaluation process. The reconstruction accuracy is evaluated using the Signal to Noise Ratio and the Spectral Angle. Additionally, a land cover classification using a multi-class Support Vector Machine is used as a target application. The classification performance of the original and reconstructed data are compared. The reconstruction accuracy of the 1D-Convolutional Autoencoder outperforms the Deep Autoencoder and Nonlinear Principal Component Analysis for the used metrics and for both data sets using a fixed compression ratio.},
	pages = {15--21},
	publisher = {Copernicus {GmbH}},
	author = {Kuester, J. 1 and Gross, W. 1 and Middelmann, W. 1 1 Fraunhofer {IOSB} and Image Exploitation, Germany and Fraunhofer {IOSB}, Ettlingen and Image Exploitation, Germany},
	urldate = {2022-10-01},
	date = {2021},
	note = {{ISSN}: 16821750
Num Pages: 15-21},
	keywords = {Hyperspectral, convolutional neural network ({CNN})},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\SU885T65\\Kuester et al. - 2021 - 1d-Convolutional Autoencoder Based Hyperspectral D.pdf:application/pdf},
}

@article{zea_leveraging_2022,
	title = {Leveraging high-throughput hyperspectral imaging technology to detect cadmium stress in two leafy green crops and accelerate soil remediation efforts},
	volume = {292},
	issn = {0269-7491},
	url = {https://www.sciencedirect.com/science/article/pii/S0269749121019874},
	doi = {10.1016/j.envpol.2021.118405},
	abstract = {Cadmium (Cd) is a toxic metal that can accumulate in soils and negatively impact crop as well as human health. Amendments like biochar have potential to address these challenges by reducing Cd bioavailability in soil, though reliance on post-harvest wet chemical methods to quantify Cd uptake have slowed efforts to identify the most effective amendments. Hyperspectral imaging ({HSI}) is a novel technology that could overcome this limitation by quantifying symptoms of Cd stress while plants are still growing. The goals of this study were to: 1) determine whether {HSI} can detect Cd stress in two distinct leafy green crops, 2) quantify whether a locally sourced biochar derived from hardwoods can reduce Cd stress and uptake in these crops, and 3) identify vegetative indices ({VIs}) that best quantify changes in plant stress responses. Experiments were conducted in a tightly controlled automated phenotyping facility that allowed all environmental factors to be kept constant except Cd concentration (0, 5 10 and 15 mg kg−1). Symptoms of Cd stress were stronger in basil (Ocimum basilicum) than kale (Brassica oleracea), and were easier to detect using {HSI}. Several {VIs} detected Cd stress in basil, but only the anthocyanin reflectance index ({ARI}) detected all levels of Cd stress in both crop species. The biochar amendment did reduce Cd uptake, especially at low Cd concentrations in kale which took up more Cd than basil. Again, the {ARI} index was the most effective in quantifying changes in plant stress mediated by the biochar. These results indicate that the biochar evaluated in this study has potential to reduce Cd bioavailability in soil, and {HSI} could be further developed to identify rates that can best achieve this benefit. The technology also may be helping in elucidating mechanisms mediating how biochar can influence plant growth and stress responses.},
	pages = {118405},
	journaltitle = {Environmental Pollution},
	shortjournal = {Environmental Pollution},
	author = {Zea, Maria and Souza, Augusto and Yang, Yang and Lee, Linda and Nemali, Krishna and Hoagland, Lori},
	urldate = {2023-04-02},
	date = {2022-01-01},
	langid = {english},
	keywords = {Basil, Biochar, Hormesis, Kale, Plant uptake, Vegetative indices},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\X62SJCS7\\Zea et al. - 2022 - Leveraging high-throughput hyperspectral imaging t.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\YH7GWHK7\\S0269749121019874.html:text/html},
}

@article{henriksen_plastic_2022,
	title = {Plastic classification via in-line hyperspectral camera analysis and unsupervised machine learning},
	volume = {118},
	issn = {0924-2031},
	url = {https://www.sciencedirect.com/science/article/pii/S0924203121001247},
	doi = {10.1016/j.vibspec.2021.103329},
	abstract = {An increase in the quality of recycled plastic is paramount to address the global plastic challenge and applicability of recycled plastics. A potent approach is mechanical plastic sorting but sufficient analytical techniques are needed. This study applies unsupervised machine learning on short wave infrared hyperspectral data to build a model for classification of plastics. The model can successfully distinguish between twelve plastics ({PE}, {PP}, {PET}, {PS}, {PVC}, {PVDF}, {POM}, {PEEK}, {ABS}, {PMMA}, {PC}, and {PA}12) and the utility is further proven by recognizing three unknown samples ({PS}, {PMMA}, {PC}). The experimental setup is constructed similar to an in-line industrial setup, and the machine learning is optimized for minimal data processing. This ensures the industrial relevance and is a stepping-stone to solve the global plastic challenge.},
	pages = {103329},
	journaltitle = {Vibrational Spectroscopy},
	shortjournal = {Vibrational Spectroscopy},
	author = {Henriksen, Martin L. and Karlsen, Celine B. and Klarskov, Pernille and Hinge, Mogens},
	urldate = {2023-04-02},
	date = {2022-01-01},
	langid = {english},
	keywords = {Principal component analysis, Hyperspectral imaging, Plastic identification, Plastic recycling},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\STCNXW5X\\Henriksen et al. - 2022 - Plastic classification via in-line hyperspectral c.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\8LFXQHQU\\S0924203121001247.html:text/html},
}

@article{guanter_enmap_2015,
	title = {The {EnMAP} Spaceborne Imaging Spectroscopy Mission for Earth Observation},
	volume = {7},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/7/7/8830},
	doi = {10.3390/rs70708830},
	abstract = {Imaging spectroscopy, also known as hyperspectral remote sensing, is based on the characterization of Earth surface materials and processes through spectrally-resolved measurements of the light interacting with matter. The potential of imaging spectroscopy for Earth remote sensing has been demonstrated since the 1980s. However, most of the developments and applications in imaging spectroscopy have largely relied on airborne spectrometers, as the amount and quality of space-based imaging spectroscopy data remain relatively low to date. The upcoming Environmental Mapping and Analysis Program ({EnMAP}) German imaging spectroscopy mission is intended to fill this gap. An overview of the main characteristics and current status of the mission is provided in this contribution. The core payload of {EnMAP} consists of a dual-spectrometer instrument measuring in the optical spectral range between 420 and 2450 nm with a spectral sampling distance varying between 5 and 12 nm and a reference signal-to-noise ratio of 400:1 in the visible and near-infrared and 180:1 in the shortwave-infrared parts of the spectrum. {EnMAP} images will cover a 30 km-wide area in the across-track direction with a ground sampling distance of 30 m. An across-track tilted observation capability will enable a target revisit time of up to four days at the Equator and better at high latitudes. {EnMAP} will contribute to the development and exploitation of spaceborne imaging spectroscopy applications by making high-quality data freely available to scientific users worldwide.},
	pages = {8830--8857},
	number = {7},
	journaltitle = {Remote Sensing},
	author = {Guanter, Luis and Kaufmann, Hermann and Segl, Karl and Foerster, Saskia and Rogass, Christian and Chabrillat, Sabine and Kuester, Theres and Hollstein, André and Rossner, Godela and Chlebek, Christian and Straif, Christoph and Fischer, Sebastian and Schrader, Stefanie and Storch, Tobias and Heiden, Uta and Mueller, Andreas and Bachmann, Martin and Mühle, Helmut and Müller, Rupert and Habermeyer, Martin and Ohndorf, Andreas and Hill, Joachim and Buddenbaum, Henning and Hostert, Patrick and Van der Linden, Sebastian and Leitão, Pedro J. and Rabe, Andreas and Doerffer, Roland and Krasemann, Hajo and Xi, Hongyan and Mauser, Wolfram and Hank, Tobias and Locherer, Matthias and Rast, Michael and Staenz, Karl and Sang, Bernhard},
	urldate = {2023-04-02},
	date = {2015-07},
	langid = {english},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Earth observation, {EnMAP}, environmental applications, hyperspectral remote sensing, imaging spectroscopy},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\ZX7JQPUP\\Guanter et al. - 2015 - The EnMAP Spaceborne Imaging Spectroscopy Mission .pdf:application/pdf},
}

@article{pascual-venteo_prototyping_2022,
	title = {Prototyping Crop Traits Retrieval Models for {CHIME}: Dimensionality Reduction Strategies Applied to {PRISMA} Data},
	volume = {14},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/14/10/2448},
	doi = {10.3390/rs14102448},
	shorttitle = {Prototyping Crop Traits Retrieval Models for {CHIME}},
	abstract = {In preparation for new-generation imaging spectrometer missions and the accompanying unprecedented inflow of hyperspectral data, optimized models are needed to generate vegetation traits routinely. Hybrid models, combining radiative transfer models with machine learning algorithms, are preferred, however, dealing with spectral collinearity imposes an additional challenge. In this study, we analyzed two spectral dimensionality reduction methods: principal component analysis ({PCA}) and band ranking ({BR}), embedded in a hybrid workflow for the retrieval of specific leaf area ({SLA}), leaf area index ({LAI}), canopy water content ({CWC}), canopy chlorophyll content ({CCC}), the fraction of absorbed photosynthetic active radiation ({FAPAR}), and fractional vegetation cover ({FVC}). The {SCOPE} model was used to simulate training data sets, which were optimized with active learning. Gaussian process regression ({GPR}) algorithms were trained over the simulations to obtain trait-specific models. The inclusion of {PCA} and {BR} with 20 features led to the so-called {GPR}-20PCA and {GPR}-20BR models. The 20PCA models encompassed over 99.95\% cumulative variance of the full spectral data, while the {GPR}-20BR models were based on the 20 most sensitive bands. Validation against in situ data obtained moderate to optimal results with normalized root mean squared error ({NRMSE}) from 13.9\% ({CWC}) to 22.3\% ({CCC}) for {GPR}-20PCA models, and {NRMSE} from 19.6\% ({CWC}) to 29.1\% ({SLA}) for {GPR}-20BR models. Overall, the {GPR}-20PCA slightly outperformed the {GPR}-20BR models for all six variables. To demonstrate mapping capabilities, both models were tested on a {PRecursore} {IperSpettrale} della Missione Applicativa ({PRISMA}) scene, spectrally resampled to Copernicus Hyperspectral Imaging Mission for the Environment ({CHIME}), over an agricultural test site (Jolanda di Savoia, Italy). The two strategies obtained plausible spatial patterns, and consistency between the two models was highest for {FVC} and {LAI} (R2=0.91, R2=0.86) and lowest for {SLA} mapping (R2=0.53). From these findings, we recommend implementing {GPR}-20PCA models as the most efficient strategy for the retrieval of multiple crop traits from hyperspectral data streams. Hence, this workflow will support and facilitate the preparations of traits retrieval models from the next-generation operational {CHIME}.},
	pages = {2448},
	number = {10},
	journaltitle = {Remote Sensing},
	author = {Pascual-Venteo, Ana B. and Portalés, Enrique and Berger, Katja and Tagliabue, Giulia and Garcia, Jose L. and Pérez-Suay, Adrián and Rivera-Caicedo, Juan Pablo and Verrelst, Jochem},
	urldate = {2023-04-02},
	date = {2022-01},
	langid = {english},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {active learning, biochemical and biophysical traits, {CHIME}, feature selection, Gaussian process regression, hybrid methods, principal component analysis, {PRISMA}},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\8LYL493V\\Pascual-Venteo et al. - 2022 - Prototyping Crop Traits Retrieval Models for CHIME.pdf:application/pdf},
}

@article{dopper_estimating_2022,
	title = {Estimating soil moisture content under grassland with hyperspectral data using radiative transfer modelling and machine learning},
	volume = {110},
	issn = {1569-8432},
	url = {https://www.sciencedirect.com/science/article/pii/S156984322200019X},
	doi = {10.1016/j.jag.2022.102817},
	abstract = {The monitoring of soil moisture content ({SMC}) at very high spatial resolution ({\textless}10m) using unmanned aerial systems ({UAS}) is of high interest for precision agriculture and the validation of large scale {SMC} products. Data-driven approaches are the most common method to retrieve {SMC} with {UAS}-borne data at water limited sites over non-disturbed agricultural crops. A major disadvantage of data-driven algorithms is the limited transferability in space and time and the need of a high number of ground reference samples. Physically-based approaches are less dependent on the amount of samples and are transferable in space and time. This study explores the potential of (1) a hybrid method targeting the soil brightness factor of the {PROSAIL} model using a variational heteroscedastic Gaussian Processes regression ({VHGPR}) algorithm, and (2) a data-driven method employing {VHGPR} for the retrieval of {SMC} over three grassland sites based on {UAS}-borne {VIS}–{NIR} (399–1001nm) hyperspectral data. The sites were managed by mowing (Fendt), grazing (Grosses Bruch) and irrigation (Marquardt). With these distinct local pre-conditions we aimed to identify factors that favor and limit the retrieval of {SMC}. The hybrid approach presented encouraging results in Marquardt ({RMSE} = 1.5Vol\_\%, R2 = 0.2). At the permanent grassland sites (Fendt, Grosses Bruch) the thatch layer jeopardized the application of the hybrid model. We identified the complex canopy structure of grassland as the main factor impacting the hybrid {SMC} retrieval. The data-driven approach showed high accuracy for Fendt (R2 = 0.84, {RMSE} = 8.66) and Marquardt (R2 = 0.4, {RMSE} = 10.52). All data-driven models build on the {LAI}-{SMC} relationship. However, this relationship was hampered by mowing (Fendt), leading to a lack of transferability in time. The alteration of plant traits by grazing prevents finding a relationship with {SMC} in Grosses Bruch. In Marquardt, we identified the timelag between changes in {SMC} and plant response as the main reason of decrease in model accuracy. Yet, the model performance is accurate in undisturbed and water-limited areas (Marquardt). The analysis points to challenges that need to be tackled in future research and opens the discussion for the development of robust models to retrieve high resolution {SMC} from {UAS}-borne remote sensing observations.},
	pages = {102817},
	journaltitle = {International Journal of Applied Earth Observation and Geoinformation},
	shortjournal = {International Journal of Applied Earth Observation and Geoinformation},
	author = {Döpper, Veronika and Rocha, Alby Duarte and Berger, Katja and Gränzig, Tobias and Verrelst, Jochem and Kleinschmit, Birgit and Förster, Michael},
	urldate = {2023-04-02},
	date = {2022-06-01},
	langid = {english},
	keywords = {Anthropogenic Influence, Gaussian Processes, Grazing, Irrigation, {LAI}, Leaf Area Index, Mowing, {PROSAIL}, Time Lag, Unmanned Aerial Systems},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\3VRYB6K3\\Döpper et al. - 2022 - Estimating soil moisture content under grassland w.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\RQGGM7CR\\S156984322200019X.html:text/html},
}

@article{bohn_glacier_2022,
	title = {Glacier Ice Surface Properties in South-West Greenland Ice Sheet: First Estimates From {PRISMA} Imaging Spectroscopy Data},
	volume = {127},
	issn = {2169-8961},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021JG006718},
	doi = {10.1029/2021JG006718},
	shorttitle = {Glacier Ice Surface Properties in South-West Greenland Ice Sheet},
	abstract = {Snow and ice melt processes on the Greenland Ice Sheet are a key in Earth's energy balance and are acutely sensitive to climate change. Melting dynamics are directly related to a decrease in surface albedo, amongst others caused by the accumulation of light-absorbing particles ({LAPs}). Featuring unique spectral patterns, these accumulations can be mapped and quantified by imaging spectroscopy. We present first results for the retrieval of glacier ice properties from the spaceborne {PRISMA} imaging spectrometer by applying a recently developed simultaneous inversion of atmospheric and surface state using optimal estimation. The image analyzed in this study was acquired over the South-West margin of the Greenland Ice Sheet in late August 2020. The area is characterized by patterns of both clean and dark ice associated with a high amount of {LAPs} deposited on the surface. We present retrieval maps and uncertainties for grain size, liquid water, and algae concentration, as well as estimated reflectance spectra for different surface properties. We then show the feasibility of using imaging spectroscopy to interpret multiband sensor data to achieve high accuracy, frequently repeated observations of changing snow and ice conditions. For example, the impurity index calculated from multiband Sentinel-3 Ocean and Land Colour Instrument measurements is dependent on dust particles, but we show that algae concentration alone can be predicted from this data with less than 20\% uncertainty. Our study evidences that present and upcoming orbital imaging spectroscopy missions such as {PRISMA}, Environmental Mapping and Analysis Program, Copernicus Hyperspectral Imaging Mission, and the Surface Biology and Geology designated observable, can significantly support research of melting ice sheets.},
	pages = {e2021JG006718},
	number = {3},
	journaltitle = {Journal of Geophysical Research: Biogeosciences},
	author = {Bohn, Niklas and Di Mauro, Biagio and Colombo, Roberto and Thompson, David R. and Susiluoto, Jouni and Carmon, Nimrod and Turmon, Michael J. and Guanter, Luis},
	urldate = {2023-04-02},
	date = {2022},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2021JG006718},
	keywords = {imaging spectroscopy, {PRISMA}, Greenland Ice Sheet, mapping glacier algae, optimal estimation, snow and ice surface properties},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CDTGX9TP\\Bohn et al. - 2022 - Glacier Ice Surface Properties in South-West Green.pdf:application/pdf;Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\SCAA9U65\\2021JG006718.html:text/html},
}

@inproceedings{aidini_hyperspectral_2019,
	location = {Pacific Grove, {CA}, {USA}},
	title = {Hyperspectral Image Compression and Super-Resolution Using Tensor Decomposition Learning},
	isbn = {978-1-72814-300-2},
	url = {https://ieeexplore.ieee.org/document/9048735/},
	doi = {10.1109/IEEECONF44664.2019.9048735},
	abstract = {As the ﬁeld of remote sensing for Earth Observation is rapidly evolving, there is an increasing demand for developing suitable methods to store and transmit the massive amounts of the generated data. At the same time, as multiple sensors acquire observations with different dimensions, super-resolution methods come into play to unify the framework for upcoming statistical inference tasks. In this paper, we employ a tensorbased structuring of multi-spectral image data and we propose a low-rank tensor completion scheme for efﬁcient image-content compression and recovery. To address the problem of lowresolution imagery, we further provide a robust algorithmic scheme for super-resolving satellite images, followed by a stateof-the-art convolutional neural network architecture serving the classiﬁcation task of the employed images. Experimental analysis on real-world observations demonstrates the detrimental effects of image compression on classiﬁcation, an issued successfully addressed by the proposed recovery and super-resolution schemes.},
	eventtitle = {2019 53rd Asilomar Conference on Signals, Systems, and Computers},
	pages = {1369--1373},
	booktitle = {2019 53rd Asilomar Conference on Signals, Systems, and Computers},
	publisher = {{IEEE}},
	author = {Aidini, A. and Giannopoulos, M. and Pentari, A. and Fotiadou, K. and Tsakalides, P.},
	urldate = {2023-04-10},
	date = {2019-11},
	langid = {english},
	file = {Aidini et al. - 2019 - Hyperspectral Image Compression and Super-Resoluti.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\N8B858V8\\Aidini et al. - 2019 - Hyperspectral Image Compression and Super-Resoluti.pdf:application/pdf},
}

@article{luo_lossless_2019,
	title = {Lossless compression for hyperspectral image using deep recurrent neural networks},
	volume = {10},
	issn = {1868-808X},
	url = {https://doi.org/10.1007/s13042-019-00937-2},
	doi = {10.1007/s13042-019-00937-2},
	abstract = {With the rapid development of hyperspectral remote sensing technology, the spatial resolution and spectral resolution of hyperspectral images are continually increasing, resulting in a continual increase in the scale of hyperspectral data. At present, hyperspectral lossless compression technology has reached a bottleneck. Simultaneously, the rise of deep learning has provided us with new ideas. Therefore, this paper examines the use of deep learning for the lossless compression of hyperspectral images. In view of the differential pulse code modulation ({DPCM}) method being insufficient for predicting spectral band information, the proposed method, called C-{DPCM}-{RNN}, uses a deep recurrent neural network ({RNN}) to improve the traditional {DPCM} method and improve the generalization ability and prediction accuracy of the model. The final experimental result shows that C-{DPCM}-{RNN} achieves better compression on a set of calibrated {AVIRIS} test images provided by the Multispectral and Hyperspectral Data Compression Working Group of the Consultative Committee for Space Data Systems in 2006. C-{DPCM}-{RNN} overcomes the limits of traditional methods in its performance on uncalibrated {AVIRIS} test images.},
	pages = {2619--2629},
	number = {10},
	journaltitle = {International Journal of Machine Learning and Cybernetics},
	shortjournal = {Int. J. Mach. Learn. \& Cyber.},
	author = {Luo, Jiqiang and Wu, Jiaji and Zhao, Shihui and Wang, Lei and Xu, Tingfa},
	urldate = {2023-04-10},
	date = {2019-10-01},
	langid = {english},
	keywords = {Deep learning, Hyperspectral images, Lossless compression},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\V7A7434K\\Luo et al. - 2019 - Lossless compression for hyperspectral image using.pdf:application/pdf},
}

@article{ulku_large-scale_2018,
	title = {Large-scale hyperspectral image compression via sparse representations based on online learning},
	volume = {28},
	issn = {2083-8492},
	url = {https://www.sciendo.com/article/10.2478/amcs-2018-0015},
	doi = {10.2478/amcs-2018-0015},
	abstract = {In this study, proximity based optimization algorithms are used for lossy compression of hyperspectral images that are inherently large scale. This is the ﬁrst time that such proximity based optimization algorithms are implemented with an online dictionary learning method. Compression performances are compared with the one obtained by various sparse representation algorithms. As a result, proximity based optimization algorithms are listed among the three best ones in terms of compression performance values for all hyperspectral images. Additionally, the applicability of anomaly detection is tested on the reconstructed images.},
	pages = {197--207},
	number = {1},
	journaltitle = {International Journal of Applied Mathematics and Computer Science},
	author = {Ülkü, İrem and Kizgut, Ersin},
	urldate = {2023-04-10},
	date = {2018-03-01},
	langid = {english},
	file = {Ülkü und Kizgut - 2018 - Large-scale hyperspectral image compression via sp.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\UMRA6TII\\Ülkü und Kizgut - 2018 - Large-scale hyperspectral image compression via sp.pdf:application/pdf},
}

@incollection{leal-taixe_onboard_2019,
	location = {Cham},
	title = {Onboard Hyperspectral Image Compression Using Compressed Sensing and Deep Learning},
	volume = {11130},
	isbn = {978-3-030-11011-6 978-3-030-11012-3},
	url = {https://link.springer.com/10.1007/978-3-030-11012-3_3},
	abstract = {We propose a real-time onboard compression scheme for hyperspectral datacube which consists of a very low complexity encoder and a deep learning based parallel decoder architecture for fast decompression. The encoder creates a set of coded snapshots from a given datacube using a measurement code matrix. The decoder decompresses the coded snapshots by using a sparse recovery algorithm. We solve this sparse recovery problem using a deep neural network for fast reconstruction. We present experimental results which demonstrate that our technique performs very well in terms of quality of reconstruction and in terms of computational requirements compared to other transform based techniques with some tradeoﬀ in {PSNR}. The proposed technique also enables faster inference in compressed domain, suitable for on-board requirements.},
	pages = {30--42},
	booktitle = {Computer Vision – {ECCV} 2018 Workshops},
	publisher = {Springer International Publishing},
	author = {Kumar, Saurabh and Chaudhuri, Subhasis and Banerjee, Biplab and Ali, Feroz},
	editor = {Leal-Taixé, Laura and Roth, Stefan},
	urldate = {2023-04-10},
	date = {2019},
	langid = {english},
	doi = {10.1007/978-3-030-11012-3_3},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Kumar et al. - 2019 - Onboard Hyperspectral Image Compression Using Comp.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\GYBTPNQN\\Kumar et al. - 2019 - Onboard Hyperspectral Image Compression Using Comp.pdf:application/pdf},
}

@inproceedings{shen_golomb-rice_2017,
	location = {Fort Worth, {TX}},
	title = {Golomb-Rice coding parameter learning using deep belief network for hyperspectral image compression},
	isbn = {978-1-5090-4951-6},
	url = {http://ieeexplore.ieee.org/document/8127434/},
	doi = {10.1109/IGARSS.2017.8127434},
	abstract = {While Golomb-Rice codes are optimal for geometrically distributed source, the practically achievable coding efﬁciency depends on the accuracy of the coding parameter estimated from the input data. Most existing methods are based on the assumption of geometric distribution and thus would suffer from a loss in coding efﬁciency if the underlying distribution deviates from the geometric distribution, which is usually the case in practice. We proposed a data-driven parameter estimation method without assuming the underlying distribution. We formulated the problem of choosing the best coding parameter for the given input data as a pattern classiﬁcation problem. To this end, we trained a deep belief network using the data segments to be coded, along with their “labels”, which are the optimal coding parameters that yield the shortest codewords. Simulations on data synthesized using statistical models, as well as data in hyperspectral image coding showed that the proposed deep learning method tended to be more robust than several state-of-the-art parameter estimation methods, with the capability to further improve the accuracies of these methods.},
	eventtitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})},
	pages = {2239--2242},
	booktitle = {2017 {IEEE} International Geoscience and Remote Sensing Symposium ({IGARSS})},
	publisher = {{IEEE}},
	author = {Shen, Hongda and Pan, W. David and Dong, Yuhang and Jiang, Zhuocheng},
	urldate = {2023-04-10},
	date = {2017-07},
	langid = {english},
	file = {Shen et al. - 2017 - Golomb-Rice coding parameter learning using deep b.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\8LGKWP44\\Shen et al. - 2017 - Golomb-Rice coding parameter learning using deep b.pdf:application/pdf},
}

@article{deng_learning-based_2020,
	title = {Learning-Based Hyperspectral Imagery Compression through Generative Neural Networks},
	volume = {12},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/12/21/3657},
	doi = {10.3390/rs12213657},
	abstract = {Hyperspectral images ({HSIs}), which obtain abundant spectral information for narrow spectral bands (no wider than 10 nm), have greatly improved our ability to qualitatively and quantitatively sense the Earth. Since {HSIs} are collected by high-resolution instruments over a very large number of wavelengths, the data generated by such sensors is enormous, and the amount of data continues to grow, {HSI} compression technique will play more crucial role in this trend. The classical method for {HSI} compression is through compression and reconstruction methods such as three-dimensional wavelet-based techniques or the principle component analysis ({PCA}) transform. In this paper, we provide an alternative approach for {HSI} compression via a generative neural network ({GNN}), which learns the probability distribution of the real data from a random latent code. This is achieved by defining a family of densities and finding the one minimizing the distance between this family and the real data distribution. Then, the well-trained neural network is a representation of the {HSI}, and the compression ratio is determined by the complexity of the {GNN}. Moreover, the latent code can be encrypted by embedding a digit with a random distribution, which makes the code confidential. Experimental examples are presented to demonstrate the potential of the {GNN} to solve image compression problems in the field of {HSI}. Compared with other algorithms, it has better performance at high compression ratio, and there is still much room left for improvements along with the fast development of deep-learning techniques.},
	pages = {3657},
	number = {21},
	journaltitle = {Remote Sensing},
	author = {Deng, Chubo and Cen, Yi and Zhang, Lifu},
	urldate = {2023-04-10},
	date = {2020-01},
	langid = {english},
	note = {Number: 21
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {compression sensing, feature reduction, generative neural network, hyperspectral},
	file = {Volltext:C\:\\Users\\Niklas\\Zotero\\storage\\QDMBVYLW\\Deng et al. - 2020 - Learning-Based Hyperspectral Imagery Compression t.pdf:application/pdf},
}

@article{hu_coarse--fine_2020,
	title = {Coarse-to-Fine Hyper-Prior Modeling for Learned Image Compression},
	volume = {34},
	rights = {Copyright (c) 2020 Association for the Advancement of Artificial Intelligence},
	issn = {2374-3468},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/6736},
	doi = {10.1609/aaai.v34i07.6736},
	abstract = {Approaches to image compression with machine learning now achieve superior performance on the compression rate compared to existing hybrid codecs. The conventional learning-based methods for image compression exploits hyper-prior and spatial context model to facilitate probability estimations. Such models have limitations in modeling long-term dependency and do not fully squeeze out the spatial redundancy in images. In this paper, we propose a coarse-to-fine framework with hierarchical layers of hyper-priors to conduct comprehensive analysis of the image and more effectively reduce spatial redundancy, which improves the rate-distortion performance of image compression significantly. Signal Preserving Hyper Transforms are designed to achieve an in-depth analysis of the latent representation and the Information Aggregation Reconstruction sub-network is proposed to maximally utilize side-information for reconstruction. Experimental results show the effectiveness of the proposed network to efficiently reduce the redundancies in images and improve the rate-distortion performance, especially for high-resolution images. Our project is publicly available at https://huzi96.github.io/coarse-to-fine-compression.html.},
	pages = {11013--11020},
	number = {7},
	journaltitle = {Proceedings of the {AAAI} Conference on Artificial Intelligence},
	author = {Hu, Yueyu and Yang, Wenhan and Liu, Jiaying},
	urldate = {2023-04-10},
	date = {2020-04-03},
	langid = {english},
	note = {Number: 07},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\76C5MKLF\\Hu et al. - 2020 - Coarse-to-Fine Hyper-Prior Modeling for Learned Im.pdf:application/pdf},
}

@misc{theis_lossy_2022,
	title = {Lossy Compression with Gaussian Diffusion},
	url = {http://arxiv.org/abs/2206.08889},
	abstract = {We consider a novel lossy compression approach based on unconditional diffusion generative models, which we call {DiffC}. Unlike modern compression schemes which rely on transform coding and quantization to restrict the transmitted information, {DiffC} relies on the efﬁcient communication of pixels corrupted by Gaussian noise. We implement a proof of concept and ﬁnd that it works surprisingly well despite the lack of an encoder transform, outperforming the state-of-the-art generative compression method {HiFiC} on {ImageNet} 64x64. {DiffC} only uses a single model to encode and denoise corrupted pixels at arbitrary bitrates. The approach further provides support for progressive coding, that is, decoding from partial bit streams. We perform a rate-distortion analysis to gain a deeper understanding of its performance, providing analytical results for multivariate Gaussian data as well as theoretic bounds for general distributions. Furthermore, we prove that a ﬂow-based reconstruction achieves a 3 {dB} gain over ancestral sampling at high bitrates.},
	number = {{arXiv}:2206.08889},
	publisher = {{arXiv}},
	author = {Theis, Lucas and Salimans, Tim and Hoffman, Matthew D. and Mentzer, Fabian},
	urldate = {2023-04-10},
	date = {2022-12-31},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {2206.08889 [cs, math, stat]},
	keywords = {Computer Science - Information Theory, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Theis et al. - 2022 - Lossy Compression with Gaussian Diffusion.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\RPP5J74J\\Theis et al. - 2022 - Lossy Compression with Gaussian Diffusion.pdf:application/pdf},
}

@article{dua_comprehensive_2020,
	title = {Comprehensive review of hyperspectral image compression algorithms},
	volume = {59},
	issn = {0091-3286, 1560-2303},
	url = {https://www.spiedigitallibrary.org/journals/optical-engineering/volume-59/issue-9/090902/Comprehensive-review-of-hyperspectral-image-compression-algorithms/10.1117/1.OE.59.9.090902.full},
	doi = {10.1117/1.OE.59.9.090902},
	abstract = {Rapid advancement in the development of hyperspectral image analysis techniques has led to specialized hyperspectral missions. It results in the bulk transmission of hyperspectral images from sensors to analysis centers and finally to data centers. Storage of these large size images is a critical issue that is handled by compression techniques. This survey focuses on different hyperspectral image compression algorithms that have been classified into two broad categories based on eight internal and six external parameters. In addition, we identified research challenges and suggested future scope for each technique. The detailed classification used in this paper can categorize other compression algorithms and may help in selecting research objectives.},
	pages = {090902},
	number = {9},
	journaltitle = {Optical Engineering},
	shortjournal = {{OE}},
	author = {Dua, Yaman and Kumar, Vinod and Singh, Ravi Shankar},
	urldate = {2023-04-10},
	date = {2020-09},
	note = {Publisher: {SPIE}},
	file = {Full Text PDF:C\:\\Users\\Niklas\\Zotero\\storage\\CJZKBW8B\\Dua et al. - 2020 - Comprehensive review of hyperspectral image compre.pdf:application/pdf},
}

@article{blau_rethinking_nodate,
	title = {Rethinking Lossy Compression: The Rate-Distortion-Perception Tradeoff},
	abstract = {Lossy compression algorithms are typically designed and analyzed through the lens of Shannon’s rate-distortion theory, where the goal is to achieve the lowest possible distortion (e.g., low {MSE} or high {SSIM}) at any given bit rate. However, in recent years, it has become increasingly accepted that “low distortion” is not a synonym for “high perceptual quality”, and in fact optimization of one often comes at the expense of the other. In light of this understanding, it is natural to seek for a generalization of rate-distortion theory which takes perceptual quality into account. In this paper, we adopt the mathematical deﬁnition of perceptual quality recently proposed by Blau \& Michaeli (2018), and use it to study the three-way tradeoff between rate, distortion, and perception. We show that restricting the perceptual quality to be high, generally leads to an elevation of the rate-distortion curve, thus necessitating a sacriﬁce in either rate or distortion. We prove several fundamental properties of this triple-tradeoff, calculate it in closed form for a Bernoulli source, and illustrate it visually on a toy {MNIST} example.},
	author = {Blau, Yochai and Michaeli, Tomer},
	langid = {english},
	file = {Blau und Michaeli - Rethinking Lossy Compression The Rate-Distortion-.pdf:C\:\\Users\\Niklas\\Zotero\\storage\\4RZK78N4\\Blau und Michaeli - Rethinking Lossy Compression The Rate-Distortion-.pdf:application/pdf},
}

@incollection{berger_rate-distortion_2003,
	title = {Rate-Distortion Theory},
	isbn = {978-0-471-21928-6},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471219282.eot142},
	abstract = {Rate-distortion theory is the branch of information theory that treats compressing the data produced by an information source down to a specified encoding rate that is strictly less than the source's entropy. This necessarily entails some lossiness, or distortion, between the original source data and the best approximation thereto that can be produced on the basis of the encoder's output bits. Rate-distortion theory was introduced in the seminal works written in 1948 and 1959 by C. E. Shannon, the founder of information theory. We describe Shannon's contribution and then trace its subsequent development worldwide. Heavier than usual emphasis is placed on the concept of “matching” a channel to a source in the rate-distortion sense, and also on the analogous matching of a source to a channel. Experimental evidence has been mounting in support of the hypothesis that living organisms often simultaneously achieve both of these matchings when processing their sensory inputs, thereby eliminating the need for the complex encoding and decoding operations that are needed in order to produce an information-theoretically optimum system in the absence of such double matching.},
	booktitle = {Wiley Encyclopedia of Telecommunications},
	publisher = {John Wiley \& Sons, Ltd},
	author = {Berger, Toby},
	urldate = {2023-04-10},
	date = {2003},
	langid = {english},
	doi = {10.1002/0471219282.eot142},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471219282.eot142},
	keywords = {bioinformation theory, distortion measure, joint source-channel coding, lossy source coding, rate-distortion, Shannon},
	file = {Snapshot:C\:\\Users\\Niklas\\Zotero\\storage\\3C25BMXI\\0471219282.html:text/html},
}
